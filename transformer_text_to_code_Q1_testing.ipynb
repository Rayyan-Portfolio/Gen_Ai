{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10860736,
          "sourceType": "datasetVersion",
          "datasetId": 6746731
        },
        {
          "sourceId": 269826,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 230911,
          "modelId": 252668
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rayyan-Portfolio/Gen_Ai/blob/main/transformer_text_to_code_Q1_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_clean_data(file_path):\n",
        "    \"\"\"Loads and cleans the dataset by selecting relevant columns,\n",
        "    removing missing values, and stripping whitespace.\"\"\"\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", usecols=['text', 'code']).dropna()\n",
        "    df['text'] = df['text'].str.strip().str.lower()\n",
        "    df['code'] = df['code'].str.strip()\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "file_path = \"/kaggle/input/spoc-train/spoc-train-train.tsv\"\n",
        "train_df = load_clean_data(file_path)\n",
        "\n",
        "# Print sample data\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T09:18:23.679486Z",
          "iopub.execute_input": "2025-02-26T09:18:23.679872Z",
          "iopub.status.idle": "2025-02-26T09:18:24.109089Z",
          "shell.execute_reply.started": "2025-02-26T09:18:23.679840Z",
          "shell.execute_reply": "2025-02-26T09:18:24.108175Z"
        },
        "id": "PXFccJzQpXR7",
        "outputId": "bc35146f-99ff-4413-e558-5cc54aadec69"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                             text                 code\n1                 create string s            string s;\n2  create integers x1, y1, x2, y2  int x1, y1, x2, y2;\n3                          read s            cin >> s;\n4             set x1 to s[0] - 96      x1 = s[0] - 96;\n5            set y1 to s[1] - '0'     y1 = s[1] - '0';",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>create string s</td>\n      <td>string s;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>create integers x1, y1, x2, y2</td>\n      <td>int x1, y1, x2, y2;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>read s</td>\n      <td>cin &gt;&gt; s;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>set x1 to s[0] - 96</td>\n      <td>x1 = s[0] - 96;</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>set y1 to s[1] - '0'</td>\n      <td>y1 = s[1] - '0';</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.encoder_layers = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_emb = self.embedding(src) + self.positional_encoding[:, :src.size(1), :]\n",
        "        return self.encoder_layers(src_emb.permute(1, 0, 2)).permute(1, 0, 2)\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.decoder_layers = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        tgt_emb = self.embedding(tgt) + self.positional_encoding[:, :tgt.size(1), :]\n",
        "        output = self.decoder_layers(tgt_emb.permute(1, 0, 2), memory.permute(1, 0, 2))\n",
        "        return self.fc_out(output.permute(1, 0, 2))\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super(TransformerSeq2Seq, self).__init__()\n",
        "        self.encoder = TransformerEncoder(input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "        self.decoder = TransformerDecoder(output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        memory = self.encoder(src)\n",
        "        output = self.decoder(tgt, memory)\n",
        "        return output\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T09:24:17.108180Z",
          "iopub.execute_input": "2025-02-26T09:24:17.108590Z",
          "iopub.status.idle": "2025-02-26T09:24:17.125952Z",
          "shell.execute_reply.started": "2025-02-26T09:24:17.108559Z",
          "shell.execute_reply": "2025-02-26T09:24:17.124798Z"
        },
        "id": "KOgX-5lWpXR-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())  # Lowercase and tokenize\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"if x > 0 then print x\"\n",
        "sample_code = \"if (x > 0) { cout << x; }\"\n",
        "\n",
        "tokenized_text = tokenize_text(sample_text)\n",
        "tokenized_code = tokenize_text(sample_code)\n",
        "\n",
        "print(\"Tokenized Text:\", tokenized_text)\n",
        "print(\"Tokenized Code:\", tokenized_code)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T09:30:41.958169Z",
          "iopub.execute_input": "2025-02-26T09:30:41.958562Z",
          "iopub.status.idle": "2025-02-26T09:30:44.200477Z",
          "shell.execute_reply.started": "2025-02-26T09:30:41.958532Z",
          "shell.execute_reply": "2025-02-26T09:30:44.199253Z"
        },
        "id": "RQP3f9dOpXR-",
        "outputId": "be5af217-2d73-4037-ef1d-aeef05976817"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nTokenized Text: ['if', 'x', '>', '0', 'then', 'print', 'x']\nTokenized Code: ['if', '(', 'x', '>', '0', ')', '{', 'cout', '<', '<', 'x', ';', '}']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "XFHNR0_5pXR_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "NU37TfHSpXR_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load and clean dataset\n",
        "def load_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", usecols=['text', 'code']).dropna()\n",
        "    df['text'] = df['text'].str.strip().str.lower()\n",
        "    df['code'] = df['code'].str.strip()\n",
        "    return df\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Build vocabulary\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(tokenize_text(text))\n",
        "    vocab = {word: idx + 2 for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<unk>'] = 1\n",
        "    return vocab\n",
        "\n",
        "# Custom dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, text_vocab, code_vocab):\n",
        "        self.data = data\n",
        "        self.text_vocab = text_vocab\n",
        "        self.code_vocab = code_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text_tokens = tokenize_text(self.data.iloc[idx]['text'])\n",
        "        code_tokens = tokenize_text(self.data.iloc[idx]['code'])\n",
        "        text_indices = [min(self.text_vocab.get(token, 1), len(self.text_vocab) - 1) for token in text_tokens]\n",
        "        code_indices = [min(self.code_vocab.get(token, 1), len(self.code_vocab) - 1) for token in code_tokens]\n",
        "\n",
        "        return torch.tensor(text_indices), torch.tensor(code_indices)\n",
        "\n",
        "# Transformer Components\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.encoder_layers = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_emb = self.embedding(src) + self.positional_encoding[:, :src.size(1), :]\n",
        "        return self.encoder_layers(src_emb.permute(1, 0, 2)).permute(1, 0, 2)\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.decoder_layers = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        tgt_emb = self.embedding(tgt) + self.positional_encoding[:, :tgt.size(1), :]\n",
        "        output = self.decoder_layers(tgt_emb.permute(1, 0, 2), memory.permute(1, 0, 2))\n",
        "        return self.fc_out(output.permute(1, 0, 2))\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.encoder = TransformerEncoder(input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "        self.decoder = TransformerDecoder(output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        memory = self.encoder(src)\n",
        "        output = self.decoder(tgt, memory)\n",
        "        return output\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:08:51.254328Z",
          "iopub.execute_input": "2025-02-26T13:08:51.254637Z",
          "iopub.status.idle": "2025-02-26T13:08:51.269171Z",
          "shell.execute_reply.started": "2025-02-26T13:08:51.254614Z",
          "shell.execute_reply": "2025-02-26T13:08:51.268012Z"
        },
        "id": "AOeE6bjMpXR_",
        "outputId": "b4e2cdd0-8240-407f-b431-31e7dd93b347"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "file_path = \"/kaggle/input/spoc-train/spoc-train-train.tsv\"\n",
        "train_df = load_clean_data(file_path)\n",
        "train_df\n",
        "# Load data\n",
        "file_path = \"/kaggle/input/spoc-train/spoc-train-test.tsv\"\n",
        "test_df = load_clean_data(file_path)\n",
        "# Load data\n",
        "file_path = \"/kaggle/input/spoc-train/spoc-train-eval.tsv\"\n",
        "eval_df = load_clean_data(file_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:08:51.549537Z",
          "iopub.execute_input": "2025-02-26T13:08:51.549751Z",
          "iopub.status.idle": "2025-02-26T13:08:51.965176Z",
          "shell.execute_reply.started": "2025-02-26T13:08:51.549733Z",
          "shell.execute_reply": "2025-02-26T13:08:51.964493Z"
        },
        "id": "7uvGUKj1pXR_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab\n",
        "text_vocab = build_vocab(train_df['text'])\n",
        "code_vocab = build_vocab(train_df['code'])\n",
        "\n",
        "# Prepare dataset and dataloader\n",
        "dataset = CodeDataset(train_df, text_vocab, code_vocab)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=lambda batch: tuple(zip(*batch)))\n",
        "\n",
        "# Model Parameters\n",
        "input_dim = len(text_vocab)\n",
        "output_dim = len(code_vocab)\n",
        "emb_dim, n_heads, num_layers, ff_dim, dropout, max_len = 256, 8, 6, 512, 0.1, 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = TransformerSeq2Seq(input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:08:51.966231Z",
          "iopub.execute_input": "2025-02-26T13:08:51.966505Z",
          "iopub.status.idle": "2025-02-26T13:09:19.641116Z",
          "shell.execute_reply.started": "2025-02-26T13:08:51.966475Z",
          "shell.execute_reply": "2025-02-26T13:09:19.639693Z"
        },
        "id": "6ONcDPFxpXSA",
        "outputId": "20f2c9fd-0643-4390-a4dc-36643ac47b44"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-280a76ea3acb>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ],
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model(model, dataloader, optimizer, criterion, epochs, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for src, tgt in dataloader:\n",
        "            src = [torch.tensor(s, dtype=torch.long) for s in src]\n",
        "            tgt = [torch.tensor(t, dtype=torch.long) for t in tgt]\n",
        "\n",
        "            # Ensure tensors are properly padded\n",
        "            src = torch.nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=0).to(device)\n",
        "            tgt = torch.nn.utils.rnn.pad_sequence(tgt, batch_first=True, padding_value=0).to(device)\n",
        "\n",
        "            # Debugging: Check max index before passing to embedding layer\n",
        "            if torch.max(src) >= input_dim or torch.max(tgt) >= output_dim:\n",
        "                print(f\"Error: Index out of bounds! Max src index: {torch.max(src)}, Max tgt index: {torch.max(tgt)}\")\n",
        "                continue  # Skip this batch to prevent crashing\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt[:, :-1])  # Shift target for teacher forcing\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), tgt[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {total_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:09:19.641580Z",
          "iopub.status.idle": "2025-02-26T13:09:19.641845Z",
          "shell.execute_reply": "2025-02-26T13:09:19.641727Z"
        },
        "id": "aivRtHnmpXSA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model(model, dataloader, optimizer, criterion, epochs=10, device=device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:09:19.642654Z",
          "iopub.status.idle": "2025-02-26T13:09:19.643135Z",
          "shell.execute_reply": "2025-02-26T13:09:19.642966Z"
        },
        "id": "A-K-UNHXpXSA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"transformer_seq2seq.pth\")\n",
        "print(\"Model saved successfully.\")\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load(\"transformer_seq2seq.pth\"))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T12:29:14.419345Z",
          "iopub.status.idle": "2025-02-26T12:29:14.419747Z",
          "shell.execute_reply": "2025-02-26T12:29:14.419585Z"
        },
        "id": "mG6VcVEhpXSA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_output(model, test_loader, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for src, _ in test_loader:\n",
        "            src = torch.nn.utils.rnn.pad_sequence(src, batch_first=True).to(device)\n",
        "            tgt = torch.full((src.shape[0], 1), code_vocab['<pad>'], dtype=torch.long, device=device)\n",
        "            for _ in range(50):\n",
        "                output = model(src, tgt)\n",
        "                next_word = output[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "                tgt = torch.cat((tgt, next_word), dim=1)\n",
        "            print(\"Generated Code:\", tgt.cpu().numpy())\n",
        "            break\n",
        "\n",
        "generate_output(model, test_loader, device)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "RgemEOHUpXSA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate predictions\n",
        "def generate_code(model, input_text, text_vocab, code_vocab, max_len=50, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize and convert text to indices\n",
        "    input_tokens = tokenize_text(input_text)\n",
        "    input_indices = [text_vocab.get(token, 1) for token in input_tokens]  # 1 = <unk>\n",
        "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    # Encode the input\n",
        "    with torch.no_grad():\n",
        "        memory = model.encoder(input_tensor)\n",
        "\n",
        "    # Start decoding with <start> token\n",
        "    tgt_indices = [code_vocab.get('<start>', 1)]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(tgt_tensor, memory)\n",
        "\n",
        "        # Get the most probable next token\n",
        "        next_token = output.argmax(-1)[:, -1].item()\n",
        "        tgt_indices.append(next_token)\n",
        "\n",
        "        # Stop if <end> token is generated\n",
        "        if next_token == code_vocab.get('<end>', 1):\n",
        "            break\n",
        "\n",
        "    # Convert indices back to tokens\n",
        "    inv_code_vocab = {idx: token for token, idx in code_vocab.items()}\n",
        "    generated_code = \" \".join(inv_code_vocab.get(idx, \"<unk>\") for idx in tgt_indices[1:])\n",
        "\n",
        "    return generated_code\n",
        "\n",
        "# Test the model with an example\n",
        "test_text = \"sort an array in ascending order\"\n",
        "predicted_code = generate_code(model, test_text, text_vocab, code_vocab, device=device)\n",
        "print(\"\\n📝 Input Text:\", test_text)\n",
        "print(\"💻 Generated Code:\", predicted_code)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T11:15:59.308007Z",
          "iopub.execute_input": "2025-02-26T11:15:59.308369Z",
          "iopub.status.idle": "2025-02-26T11:15:59.367426Z",
          "shell.execute_reply.started": "2025-02-26T11:15:59.308346Z",
          "shell.execute_reply": "2025-02-26T11:15:59.366555Z"
        },
        "id": "lEOjpmJZpXSA",
        "outputId": "4768fbba-5e7d-46b8-d1ee-ffe0c0d0e205"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n📝 Input Text: sort an array in ascending order\n💻 Generated Code: <unk>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import heapq\n",
        "\n",
        "def generate_code_beam_search(model, input_text, text_vocab, code_vocab, max_len=50, beam_size=3, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize and convert text to indices\n",
        "    input_tokens = tokenize_text(input_text)\n",
        "    input_indices = [text_vocab.get(token, 1) for token in input_tokens]  # 1 = <unk>\n",
        "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    # Encode the input\n",
        "    with torch.no_grad():\n",
        "        memory = model.encoder(input_tensor)\n",
        "\n",
        "    # Start decoding with <start> token\n",
        "    start_token = code_vocab.get('<start>', 1)\n",
        "    end_token = code_vocab.get('<end>', 1)\n",
        "\n",
        "    # Beam search: Maintain multiple candidates\n",
        "    beam = [(0, [start_token])]  # (score, sequence)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        new_beam = []\n",
        "        for score, seq in beam:\n",
        "            tgt_tensor = torch.tensor(seq).unsqueeze(0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model.decoder(tgt_tensor, memory)\n",
        "\n",
        "            # Get top `beam_size` next tokens\n",
        "            probs = torch.nn.functional.log_softmax(output[:, -1, :], dim=-1)\n",
        "            top_scores, top_tokens = torch.topk(probs, beam_size)\n",
        "\n",
        "            for new_score, token in zip(top_scores[0], top_tokens[0]):\n",
        "                new_seq = seq + [token.item()]\n",
        "                new_beam.append((score + new_score.item(), new_seq))\n",
        "\n",
        "        # Keep `beam_size` best sequences\n",
        "        beam = heapq.nlargest(beam_size, new_beam, key=lambda x: x[0])\n",
        "\n",
        "        # Stop if all candidates end with <end>\n",
        "        if all(seq[-1] == end_token for _, seq in beam):\n",
        "            break\n",
        "\n",
        "    # Get the best sequence\n",
        "    best_seq = max(beam, key=lambda x: x[0])[1]\n",
        "\n",
        "    # Convert indices back to tokens\n",
        "    inv_code_vocab = {idx: token for token, idx in code_vocab.items()}\n",
        "    generated_code = \" \".join(inv_code_vocab.get(idx, \"<unk>\") for idx in best_seq[1:])  # Skip <start>\n",
        "\n",
        "    return generated_code\n",
        "\n",
        "# Test with beam search\n",
        "test_text = \"sort an array in ascending order\"\n",
        "predicted_code = generate_code_beam_search(model, test_text, text_vocab, code_vocab, device=device)\n",
        "print(\"\\n📝 Input Text:\", test_text)\n",
        "print(\"💻 Generated Code:\", predicted_code)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T11:25:54.570958Z",
          "iopub.execute_input": "2025-02-26T11:25:54.571274Z",
          "iopub.status.idle": "2025-02-26T11:25:55.527388Z",
          "shell.execute_reply.started": "2025-02-26T11:25:54.571253Z",
          "shell.execute_reply": "2025-02-26T11:25:55.526579Z"
        },
        "id": "ZjTPokDdpXSB",
        "outputId": "8736369d-93b1-4bd0-b0f0-8c2fd1448f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n📝 Input Text: sort an array in ascending order\n💻 Generated Code: <unk> ; <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "1AHd2UIWpXSC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "C5dWyBH_pXSC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING NEW CODE"
      ],
      "metadata": {
        "id": "EDNdD4H7pXSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load and clean dataset\n",
        "def load_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", usecols=['text', 'code']).dropna()\n",
        "    df['text'] = df['text'].str.strip().str.lower()\n",
        "    df['code'] = df['code'].str.strip()\n",
        "    return df\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Build vocabulary\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(tokenize_text(text))\n",
        "    vocab = {word: idx + 2 for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<unk>'] = 1\n",
        "    return vocab\n",
        "\n",
        "# Custom dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, text_vocab, code_vocab):\n",
        "        self.data = data\n",
        "        self.text_vocab = text_vocab\n",
        "        self.code_vocab = code_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text_tokens = tokenize_text(self.data.iloc[idx]['text'])\n",
        "        code_tokens = tokenize_text(self.data.iloc[idx]['code'])\n",
        "        text_indices = [self.text_vocab.get(token, 1) for token in text_tokens]  # 1 = <unk>\n",
        "        code_indices = [self.code_vocab.get(token, 1) for token in code_tokens]  # 1 = <unk>\n",
        "        return torch.tensor(text_indices), torch.tensor(code_indices)\n",
        "\n",
        "# Padding function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)  # Unzipping batch into src and tgt\n",
        "    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "    return src_padded, tgt_padded\n",
        "\n",
        "# Transformer Components\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.encoder_layers = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_emb = self.embedding(src) + self.positional_encoding[:, :src.size(1), :]\n",
        "        return self.encoder_layers(src_emb.permute(1, 0, 2)).permute(1, 0, 2)\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.decoder_layers = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        tgt_emb = self.embedding(tgt) + self.positional_encoding[:, :tgt.size(1), :]\n",
        "        output = self.decoder_layers(tgt_emb.permute(1, 0, 2), memory.permute(1, 0, 2))\n",
        "        return self.fc_out(output.permute(1, 0, 2))\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.encoder = TransformerEncoder(input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "        self.decoder = TransformerDecoder(output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        memory = self.encoder(src)\n",
        "        output = self.decoder(tgt, memory)\n",
        "        return output\n",
        "\n",
        "# Load data\n",
        "file_path = \"/kaggle/input/spoc-train/spoc-train-train.tsv\"\n",
        "train_df = load_clean_data(file_path)\n",
        "file_path = \"/kaggle/input/spoc-train/spoc-train-test.tsv\"\n",
        "test_df = load_clean_data(file_path)\n",
        "file_path = \"/kaggle/input/spoc-train/spoc-train-eval.tsv\"\n",
        "eval_df = load_clean_data(file_path)\n",
        "\n",
        "# Build vocab\n",
        "text_vocab = build_vocab(train_df['text'])\n",
        "code_vocab = build_vocab(train_df['code'])\n",
        "\n",
        "# Prepare dataset and dataloader\n",
        "dataset = CodeDataset(train_df, text_vocab, code_vocab)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Model Parameters\n",
        "input_dim = len(text_vocab)\n",
        "output_dim = len(code_vocab)\n",
        "emb_dim, n_heads, num_layers, ff_dim, dropout, max_len = 256, 8, 6, 512, 0.1, 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = TransformerSeq2Seq(input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding index\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, train_loader, optimizer, criterion, epochs, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            src, tgt = batch  # Now correctly structured as tensors\n",
        "            src, tgt = src.to(device), tgt.to(device)  # Move tensors to device\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt[:, :-1])\n",
        "\n",
        "            loss = criterion(output.reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        train_perplexity = torch.exp(torch.tensor(avg_train_loss))\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        print(f'\\nEpoch {epoch+1}/{epochs} - {epoch_time:.2f}s')\n",
        "        print(f'Train Loss: {avg_train_loss:.4f} - Train Perplexity: {train_perplexity:.2f}')\n",
        "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}\\n')\n",
        "\n",
        "#train_model(model, dataloader, optimizer, criterion, epochs=10, device=device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:01:59.384236Z",
          "iopub.execute_input": "2025-02-26T13:01:59.384574Z",
          "iopub.status.idle": "2025-02-26T13:02:27.523680Z",
          "shell.execute_reply.started": "2025-02-26T13:01:59.384546Z",
          "shell.execute_reply": "2025-02-26T13:02:27.522446Z"
        },
        "id": "PR4NA6AJpXSD",
        "outputId": "e90914c2-7c17-422c-8693-70774fb1aa1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-78feabb73c0e>\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ignore padding index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ],
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "tp6EofJwpXSD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "cACBobLmpXSD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "9uaBsUMupXSD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "kN9tTa9xpXSE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "kh_gAKiApXSE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "IkfcIkq4pXSE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOM TESTING\n"
      ],
      "metadata": {
        "id": "jQqAvr4gpXSE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "a6VqAforpXSE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load and clean dataset\n",
        "def load_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", usecols=['text', 'code']).dropna()\n",
        "    df['text'] = df['text'].str.strip().str.lower()\n",
        "    df['code'] = df['code'].str.strip()\n",
        "    return df\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Build vocabulary\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(tokenize_text(text))\n",
        "    vocab = {word: idx + 2 for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<unk>'] = 1\n",
        "    return vocab\n",
        "\n",
        "# Custom dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, text_vocab, code_vocab):\n",
        "        self.data = data\n",
        "        self.text_vocab = text_vocab\n",
        "        self.code_vocab = code_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text_tokens = tokenize_text(self.data.iloc[idx]['text'])\n",
        "        code_tokens = tokenize_text(self.data.iloc[idx]['code'])\n",
        "        text_indices = [self.text_vocab.get(token, 1) for token in text_tokens]  # 1 = <unk>\n",
        "        code_indices = [self.code_vocab.get(token, 1) for token in code_tokens]\n",
        "        return torch.tensor(text_indices), torch.tensor(code_indices)\n",
        "\n",
        "# Transformer Components\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.encoder_layers = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_emb = self.embedding(src) + self.positional_encoding[:, :src.size(1), :]\n",
        "        return self.encoder_layers(src_emb.permute(1, 0, 2)).permute(1, 0, 2)\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.decoder_layers = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        tgt_emb = self.embedding(tgt) + self.positional_encoding[:, :tgt.size(1), :]\n",
        "        output = self.decoder_layers(tgt_emb.permute(1, 0, 2), memory.permute(1, 0, 2))\n",
        "        return self.fc_out(output.permute(1, 0, 2))\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.encoder = TransformerEncoder(input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "        self.decoder = TransformerDecoder(output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        memory = self.encoder(src)\n",
        "        output = self.decoder(tgt, memory)\n",
        "        return output\n",
        "\n",
        "# Load data\n",
        "train_df = load_clean_data(\"/kaggle/input/spoc-train/spoc-train-train.tsv\")\n",
        "test_df = load_clean_data(\"/kaggle/input/spoc-train/spoc-train-test.tsv\")\n",
        "eval_df = load_clean_data(\"/kaggle/input/spoc-train/spoc-train-eval.tsv\")\n",
        "\n",
        "# Build vocab\n",
        "text_vocab = build_vocab(train_df['text'])\n",
        "code_vocab = build_vocab(train_df['code'])\n",
        "\n",
        "# Prepare dataset and dataloader\n",
        "train_loader = DataLoader(CodeDataset(train_df, text_vocab, code_vocab), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(CodeDataset(test_df, text_vocab, code_vocab), batch_size=32, shuffle=False)\n",
        "\n",
        "# Model Parameters\n",
        "input_dim = len(text_vocab)\n",
        "output_dim = len(code_vocab)\n",
        "emb_dim, n_heads, num_layers, ff_dim, dropout, max_len = 256, 8, 6, 512, 0.1, 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = TransformerSeq2Seq(input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(model, train_loader, optimizer, criterion, epochs, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for src, tgt in train_loader:\n",
        "            src = torch.nn.utils.rnn.pad_sequence(src, batch_first=True).to(device)\n",
        "            tgt = torch.nn.utils.rnn.pad_sequence(tgt, batch_first=True).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), tgt[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T12:03:17.243207Z",
          "iopub.execute_input": "2025-02-26T12:03:17.243571Z",
          "iopub.status.idle": "2025-02-26T12:03:46.562604Z",
          "shell.execute_reply.started": "2025-02-26T12:03:17.243543Z",
          "shell.execute_reply": "2025-02-26T12:03:46.561651Z"
        },
        "id": "j_19CTDFpXSE",
        "outputId": "fa6d4323-f5eb-47c0-d2b5-e4f77437ea51"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, optimizer, criterion, epochs=10, device=device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T12:04:40.289480Z",
          "iopub.execute_input": "2025-02-26T12:04:40.289841Z",
          "iopub.status.idle": "2025-02-26T12:04:40.386559Z",
          "shell.execute_reply.started": "2025-02-26T12:04:40.289814Z",
          "shell.execute_reply": "2025-02-26T12:04:40.385406Z"
        },
        "id": "tpislYPGpXSE",
        "outputId": "237f16c3-93f9-4468-9e31-dd3281a56bd8"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ecc9fb551b9d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-4bf9672255b0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion, epochs, device)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [5] at entry 0 and [4] at entry 1"
          ],
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [5] at entry 0 and [4] at entry 1",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"transformer_seq2seq.pth\")\n",
        "print(\"Model saved successfully.\")\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load(\"transformer_seq2seq.pth\"))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "MIIQtlvApXSE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def generate_output(model, test_loader, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for src, _ in test_loader:\n",
        "            src = torch.nn.utils.rnn.pad_sequence(src, batch_first=True).to(device)\n",
        "            tgt = torch.full((src.shape[0], 1), code_vocab['<pad>'], dtype=torch.long, device=device)\n",
        "            for _ in range(50):\n",
        "                output = model(src, tgt)\n",
        "                next_word = output[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "                tgt = torch.cat((tgt, next_word), dim=1)\n",
        "            print(\"Generated Code:\", tgt.cpu().numpy())\n",
        "            break\n",
        "\n",
        "generate_output(model, test_loader, device)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wo-Yd3EipXSE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "KndK16pipXSF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "RXkGSaGIpXSF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load and clean dataset\n",
        "def load_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", usecols=['text', 'code']).dropna()\n",
        "    df['text'] = df['text'].str.strip().str.lower()\n",
        "    df['code'] = df['code'].str.strip()\n",
        "    return df\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Build vocabulary\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(tokenize_text(text))\n",
        "    vocab = {word: idx + 2 for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<unk>'] = 1\n",
        "    return vocab\n",
        "\n",
        "# Custom dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, text_vocab, code_vocab):\n",
        "        self.data = data\n",
        "        self.text_vocab = text_vocab\n",
        "        self.code_vocab = code_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text_tokens = tokenize_text(self.data.iloc[idx]['text'])\n",
        "        code_tokens = tokenize_text(self.data.iloc[idx]['code'])\n",
        "        text_indices = [self.text_vocab.get(token, 1) for token in text_tokens]  # 1 = <unk>\n",
        "        code_indices = [self.code_vocab.get(token, 1) for token in code_tokens]\n",
        "        return torch.tensor(text_indices), torch.tensor(code_indices)\n",
        "\n",
        "# Custom collate function for padding\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "    return src_padded, tgt_padded\n",
        "\n",
        "# Transformer Components\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.encoder_layers = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout, batch_first=True),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_emb = self.embedding(src) + self.positional_encoding[:, :src.size(1), :]\n",
        "        return self.encoder_layers(src_emb)\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
        "        self.decoder_layers = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout, batch_first=True),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        tgt_emb = self.embedding(tgt) + self.positional_encoding[:, :tgt.size(1), :]\n",
        "        output = self.decoder_layers(tgt_emb, memory)\n",
        "        return self.fc_out(output)\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.encoder = TransformerEncoder(input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "        self.decoder = TransformerDecoder(output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        memory = self.encoder(src)\n",
        "        output = self.decoder(tgt, memory)\n",
        "        return output\n",
        "\n",
        "# Load data\n",
        "train_df = load_clean_data(\"/kaggle/input/spoc-train/spoc-train-train.tsv\")\n",
        "test_df = load_clean_data(\"/kaggle/input/spoc-train/spoc-train-test.tsv\")\n",
        "eval_df = load_clean_data(\"/kaggle/input/spoc-train/spoc-train-eval.tsv\")\n",
        "\n",
        "# Build vocab\n",
        "text_vocab = build_vocab(train_df['text'])\n",
        "code_vocab = build_vocab(train_df['code'])\n",
        "\n",
        "# Prepare dataset and dataloader\n",
        "train_loader = DataLoader(CodeDataset(train_df, text_vocab, code_vocab), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(CodeDataset(test_df, text_vocab, code_vocab), batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Model Parameters\n",
        "input_dim = len(text_vocab)\n",
        "output_dim = len(code_vocab)\n",
        "emb_dim, n_heads, num_layers, ff_dim, dropout, max_len = 256, 8, 6, 512, 0.1, 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = TransformerSeq2Seq(input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(model, train_loader, optimizer, criterion, epochs, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for src, tgt in train_loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt[:, :-1].contiguous())\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), tgt[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "train_model(model, train_loader, optimizer, criterion, epochs=10, device=device)\n",
        "\n",
        "torch.save(model.state_dict(), \"transformer_seq2seq.pth\")\n",
        "print(\"Model saved successfully.\")\n",
        "\n",
        "# Load model\n",
        "model.load_state_dict(torch.load(\"transformer_seq2seq.pth\"))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "def generate_output(model, test_loader, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for src, _ in test_loader:\n",
        "            src = src.to(device)\n",
        "            tgt = torch.full((src.shape[0], 1), code_vocab['<pad>'], dtype=torch.long, device=device)\n",
        "            for _ in range(50):\n",
        "                output = model(src, tgt)\n",
        "                next_word = output[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "                tgt = torch.cat((tgt, next_word), dim=1)\n",
        "            print(\"Generated Code:\", tgt.cpu().numpy())\n",
        "            break\n",
        "\n",
        "generate_output(model, test_loader, device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T12:21:38.172475Z",
          "iopub.execute_input": "2025-02-26T12:21:38.172877Z",
          "iopub.status.idle": "2025-02-26T12:22:11.346392Z",
          "shell.execute_reply.started": "2025-02-26T12:21:38.172849Z",
          "shell.execute_reply": "2025-02-26T12:22:11.344968Z"
        },
        "id": "DPIhY_JqpXSF",
        "outputId": "85dc9b54-d53d-47c0-8f0d-23aa839bf55d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-30b2358d974a>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ],
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "-8rCGcnwpXSF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "THcijgj5pXSF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "AxabFGx1pXSF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "6LFOupWzpXSF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "jLRpvHcvpXSF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "dOiw3dQxpXSG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "5LumS7E2pXSb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "hTYzYl64pXSb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRYING DIfferent Approach!"
      ],
      "metadata": {
        "id": "ZdJR2KpwpXSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset (replace 'dataset.csv' with your actual file path)\n",
        "data = load_clean_data('/kaggle/input/spoc-data/spoc-train.tsv')\n",
        "\n",
        "# Keep only 'text' and 'code' columns\n",
        "data = data[['text', 'code']]\n",
        "\n",
        "# Check for missing values and drop them if any\n",
        "data = data.dropna()\n",
        "data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:34:23.054652Z",
          "iopub.execute_input": "2025-02-26T13:34:23.054980Z",
          "iopub.status.idle": "2025-02-26T13:34:23.503740Z",
          "shell.execute_reply.started": "2025-02-26T13:34:23.054954Z",
          "shell.execute_reply": "2025-02-26T13:34:23.502862Z"
        },
        "id": "AO1s4rhKpXSb",
        "outputId": "c4d24f69-c9f0-425e-96a7-c11e0ca46bdc"
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   text  \\\n0                     in the function gcd(a,b=integers)   \n1       if b=1 return a, else call function gcd(b, a%b)   \n4                    n , nn, ans = integers with ans =0   \n5                                                read n   \n6                                for i=2 to n-1 execute   \n...                                                 ...   \n293846                           set sum to sum1 + sum2   \n293847                                  if sum % 2 is 0   \n293848             print \"chat with her!\" print newline   \n293849                                             else   \n293850                print \"ignore him!\" print newline   \n\n                                      code  \n0                  int gcd(int a, int b) {  \n1           return !b ? a : gcd(b, a % b);  \n4                      int n, nn, ans = 0;  \n5                                cin >> n;  \n6       for (int i = 2; i <= n - 1; ++i) {  \n...                                    ...  \n293846                  sum = sum1 + sum2;  \n293847                 if (sum % 2 == 0) {  \n293848   cout << \"CHAT WITH HER!\" << endl;  \n293849                            } else {  \n293850      cout << \"IGNORE HIM!\" << endl;  \n\n[216225 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>in the function gcd(a,b=integers)</td>\n      <td>int gcd(int a, int b) {</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>if b=1 return a, else call function gcd(b, a%b)</td>\n      <td>return !b ? a : gcd(b, a % b);</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n , nn, ans = integers with ans =0</td>\n      <td>int n, nn, ans = 0;</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>read n</td>\n      <td>cin &gt;&gt; n;</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>for i=2 to n-1 execute</td>\n      <td>for (int i = 2; i &lt;= n - 1; ++i) {</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>293846</th>\n      <td>set sum to sum1 + sum2</td>\n      <td>sum = sum1 + sum2;</td>\n    </tr>\n    <tr>\n      <th>293847</th>\n      <td>if sum % 2 is 0</td>\n      <td>if (sum % 2 == 0) {</td>\n    </tr>\n    <tr>\n      <th>293848</th>\n      <td>print \"chat with her!\" print newline</td>\n      <td>cout &lt;&lt; \"CHAT WITH HER!\" &lt;&lt; endl;</td>\n    </tr>\n    <tr>\n      <th>293849</th>\n      <td>else</td>\n      <td>} else {</td>\n    </tr>\n    <tr>\n      <th>293850</th>\n      <td>print \"ignore him!\" print newline</td>\n      <td>cout &lt;&lt; \"IGNORE HIM!\" &lt;&lt; endl;</td>\n    </tr>\n  </tbody>\n</table>\n<p>216225 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train (80%) and temp (20%)\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split temp into validation (10%) and test (10%)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:35:15.527549Z",
          "iopub.execute_input": "2025-02-26T13:35:15.527879Z",
          "iopub.status.idle": "2025-02-26T13:35:15.561785Z",
          "shell.execute_reply.started": "2025-02-26T13:35:15.527855Z",
          "shell.execute_reply": "2025-02-26T13:35:15.561002Z"
        },
        "id": "eA0B7FX5pXSc",
        "outputId": "4b7058e5-23c7-4749-8261-253562cfd5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training samples: 172980\nValidation samples: 21622\nTest samples: 21623\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple tokenizer (splits on spaces)\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Build vocabularies from training data\n",
        "def build_vocab(data, tokenizer):\n",
        "    tokens = set()\n",
        "    for item in data:\n",
        "        tokens.update(tokenizer(item))\n",
        "    # Reserve 0 for padding, 1 for <sos>, 2 for <eos>\n",
        "    vocab = {token: idx for idx, token in enumerate(tokens, start=3)}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<sos>'] = 1\n",
        "    vocab['<eos>'] = 2\n",
        "    return vocab\n",
        "\n",
        "# Create vocabularies\n",
        "pseudocode_vocab = build_vocab(train_data['text'], tokenize)\n",
        "cpp_vocab = build_vocab(train_data['code'], tokenize)\n",
        "\n",
        "# Inverse vocabularies for decoding (optional)\n",
        "inv_cpp_vocab = {idx: token for token, idx in cpp_vocab.items()}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:35:27.344338Z",
          "iopub.execute_input": "2025-02-26T13:35:27.344626Z",
          "iopub.status.idle": "2025-02-26T13:35:27.676726Z",
          "shell.execute_reply.started": "2025-02-26T13:35:27.344604Z",
          "shell.execute_reply": "2025-02-26T13:35:27.675349Z"
        },
        "id": "JWNRfAsCpXSc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, pseudocode_vocab, cpp_vocab, tokenizer):\n",
        "        self.data = data\n",
        "        self.pseudocode_vocab = pseudocode_vocab\n",
        "        self.cpp_vocab = cpp_vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pseudocode = self.data.iloc[idx]['text']\n",
        "        cpp = self.data.iloc[idx]['code']\n",
        "        # Add special tokens\n",
        "        pseudo_tokens = ['<sos>'] + self.tokenizer(pseudocode) + ['<eos>']\n",
        "        cpp_tokens = ['<sos>'] + self.tokenizer(cpp) + ['<eos>']\n",
        "        # Convert to indices\n",
        "        pseudo_indices = [self.pseudocode_vocab.get(token, 0) for token in pseudo_tokens]\n",
        "        cpp_indices = [self.cpp_vocab.get(token, 0) for token in cpp_tokens]\n",
        "        return torch.tensor(pseudo_indices), torch.tensor(cpp_indices)\n",
        "\n",
        "# Padding function for batches\n",
        "def collate_fn(batch):\n",
        "    pseudocode, cpp = zip(*batch)\n",
        "    pseudocode = torch.nn.utils.rnn.pad_sequence(pseudocode, padding_value=0, batch_first=True)\n",
        "    cpp = torch.nn.utils.rnn.pad_sequence(cpp, padding_value=0, batch_first=True)\n",
        "    return pseudocode, cpp\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = CodeDataset(train_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "val_dataset = CodeDataset(val_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "test_dataset = CodeDataset(test_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:35:39.320525Z",
          "iopub.execute_input": "2025-02-26T13:35:39.320857Z",
          "iopub.status.idle": "2025-02-26T13:35:39.352956Z",
          "shell.execute_reply.started": "2025-02-26T13:35:39.320804Z",
          "shell.execute_reply": "2025-02-26T13:35:39.351997Z"
        },
        "id": "cGF8ok-hpXSc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attn, V), attn\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size = Q.size(0)\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        output, attn = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.W_o(output)\n",
        "\n",
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha(x, x, x, mask)))\n",
        "        x = self.norm2(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha1(x, x, x, tgt_mask)))\n",
        "        x = self.norm2(x + self.dropout(self.mha2(x, enc_output, enc_output, src_mask)))\n",
        "        x = self.norm3(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "# Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=2048, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # Padding mask\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        nopeak_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len)).bool().to(tgt.device)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2) & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.create_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.pos_encoding(self.src_embedding(src) * math.sqrt(self.d_model)))\n",
        "        tgt_embedded = self.dropout(self.pos_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(dec_output)\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer(\n",
        "    src_vocab_size=len(pseudocode_vocab),\n",
        "    tgt_vocab_size=len(cpp_vocab),\n",
        "    d_model=512,\n",
        "    num_heads=8,\n",
        "    num_layers=6,\n",
        "    d_ff=2048,\n",
        "    dropout=0.1\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:36:33.489650Z",
          "iopub.execute_input": "2025-02-26T13:36:33.490106Z",
          "iopub.status.idle": "2025-02-26T13:36:34.331166Z",
          "shell.execute_reply.started": "2025-02-26T13:36:33.490068Z",
          "shell.execute_reply": "2025-02-26T13:36:34.330189Z"
        },
        "id": "wNzrM2QfpXSc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    for pseudocode, cpp in train_loader:\n",
        "        pseudocode, cpp = pseudocode, cpp\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Decoder input: <sos> + target[:-1]\n",
        "        # Target output: target[1:] + <eos>\n",
        "        output = model(pseudocode, cpp[:, :-1])\n",
        "        loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for pseudocode, cpp in val_loader:\n",
        "            pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Display results\n",
        "    epoch_time = end_time - start_time\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, Val Loss: {val_loss:.4f}, LR: {lr:.6f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:38:35.830982Z",
          "iopub.execute_input": "2025-02-26T13:38:35.831292Z",
          "iopub.status.idle": "2025-02-26T13:38:37.195904Z",
          "shell.execute_reply.started": "2025-02-26T13:38:35.831266Z",
          "shell.execute_reply": "2025-02-26T13:38:37.194752Z"
        },
        "id": "3rzDqflUpXSc",
        "outputId": "09fa6558-772e-40d5-f816-b5c3b7a7eade"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-5b579ece8755>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_graph_capture_health_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         ):\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mcapturing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_current_stream_capturing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             if capturing and not all(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py\u001b[0m in \u001b[0;36mis_current_stream_capturing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mIf\u001b[0m \u001b[0ma\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexist\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0minitializing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_cuda_isCurrentStreamCapturing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ],
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Optional: Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for pseudocode, cpp in test_loader:\n",
        "        pseudocode, cpp = pseudocode, cpp\n",
        "        output = model(pseudocode, cpp[:, :-1])\n",
        "        loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "        test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "umupUYTbpXSc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Yd7AiOiEpXSc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "MKumtcuLpXSc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "t90G6aKbpXSc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "TZJolCxapXSc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "4oa0DG7QpXSd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import time\n",
        "import math\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load and clean dataset\n",
        "def load_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep=\"\\t\", usecols=['text', 'code']).dropna()\n",
        "    df['text'] = df['text'].str.strip().str.lower()\n",
        "    df['code'] = df['code'].str.strip()\n",
        "    return df\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Build vocabulary\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(tokenize_text(text))\n",
        "    vocab = {word: idx + 4 for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<unk>'] = 1\n",
        "    vocab['<sos>'] = 2\n",
        "    vocab['<eos>'] = 3\n",
        "    return vocab\n",
        "\n",
        "# Custom dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, text_vocab, code_vocab):\n",
        "        self.data = data\n",
        "        self.text_vocab = text_vocab\n",
        "        self.code_vocab = code_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text_tokens = tokenize_text(self.data.iloc[idx]['text'])\n",
        "        code_tokens = tokenize_text(self.data.iloc[idx]['code'])\n",
        "        text_indices = [self.text_vocab.get(token, 1) for token in text_tokens]  # 1 = <unk>\n",
        "        code_indices = [self.code_vocab.get(token, 1) for token in code_tokens]\n",
        "        code_indices = [2] + code_indices + [3]  # Add <sos> and <eos>\n",
        "        return torch.tensor(text_indices), torch.tensor(code_indices)\n",
        "\n",
        "# Custom collate function for padding\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "    return src_padded, tgt_padded\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# Transformer Components\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.positional_encoding = PositionalEncoding(emb_dim, max_len)\n",
        "        self.encoder_layers = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout, batch_first=True),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, src, src_mask=None):\n",
        "        src_emb = self.embedding(src)\n",
        "        src_emb = self.positional_encoding(src_emb)\n",
        "        return self.encoder_layers(src_emb, src_key_padding_mask=src_mask)\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.positional_encoding = PositionalEncoding(emb_dim, max_len)\n",
        "        self.decoder_layers = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout, batch_first=True),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, tgt_key_padding_mask=None):\n",
        "        tgt_emb = self.embedding(tgt)\n",
        "        tgt_emb = self.positional_encoding(tgt_emb)\n",
        "        output = self.decoder_layers(tgt_emb, memory, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
        "        return self.fc_out(output)\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len):\n",
        "        super().__init__()\n",
        "        self.encoder = TransformerEncoder(input_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "        self.decoder = TransformerDecoder(output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = (src == 0).transpose(0, 1)\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "        memory = self.encoder(src, src_mask)\n",
        "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, tgt_key_padding_mask=(tgt == 0))\n",
        "        return output\n",
        "\n",
        "# Model Parameters\n",
        "input_dim = len(text_vocab)\n",
        "output_dim = len(code_vocab)\n",
        "emb_dim, n_heads, num_layers, ff_dim, dropout, max_len = 256, 8, 6, 512, 0.1, 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = TransformerSeq2Seq(input_dim, output_dim, emb_dim, n_heads, num_layers, ff_dim, dropout, max_len).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "torch.save(model.state_dict(), \"transformer_seq2seq.pth\")\n",
        "print(\"Model saved successfully.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T13:56:13.170933Z",
          "iopub.execute_input": "2025-02-26T13:56:13.171249Z",
          "iopub.status.idle": "2025-02-26T13:56:13.319001Z",
          "shell.execute_reply.started": "2025-02-26T13:56:13.171221Z",
          "shell.execute_reply": "2025-02-26T13:56:13.317962Z"
        },
        "id": "XEusV93jpXSd",
        "outputId": "7450fe56-2e07-495d-fb08-dde6c83f7598"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-ab30921d4bb9>\u001b[0m in \u001b[0;36m<cell line: 129>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ],
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "aNVlzRSfpXSd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "eO8n9OMDpXSd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***TESTING WITH HELP***"
      ],
      "metadata": {
        "id": "iWhopFfupXSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/kaggle/input/spoc-data/spoc-train.tsv'\n",
        "data = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Display the first few rows of the dataset to inspect\n",
        "data.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:17:23.264857Z",
          "iopub.execute_input": "2025-02-26T14:17:23.265176Z",
          "iopub.status.idle": "2025-02-26T14:17:23.605461Z",
          "shell.execute_reply.started": "2025-02-26T14:17:23.265150Z",
          "shell.execute_reply": "2025-02-26T14:17:23.604580Z"
        },
        "id": "uEPX1pKIpXSd",
        "outputId": "939528f1-7d9e-4c29-dbb1-2800e238c2cf"
      },
      "outputs": [
        {
          "execution_count": 54,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              text  \\\n0                in the function gcd(a,b=integers)   \n1  if b=1 return a, else call function gcd(b, a%b)   \n2                                              NaN   \n3                                              NaN   \n4               n , nn, ans = integers with ans =0   \n\n                             code  workerid probid     subid  line  indent  \n0         int gcd(int a, int b) {        38    13A  41120785     0       0  \n1  return !b ? a : gcd(b, a % b);        38    13A  41120785     1       1  \n2                               }        38    13A  41120785     2       0  \n3                    int main() {        38    13A  41120785     3       0  \n4             int n, nn, ans = 0;        38    13A  41120785     4       1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>code</th>\n      <th>workerid</th>\n      <th>probid</th>\n      <th>subid</th>\n      <th>line</th>\n      <th>indent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>in the function gcd(a,b=integers)</td>\n      <td>int gcd(int a, int b) {</td>\n      <td>38</td>\n      <td>13A</td>\n      <td>41120785</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>if b=1 return a, else call function gcd(b, a%b)</td>\n      <td>return !b ? a : gcd(b, a % b);</td>\n      <td>38</td>\n      <td>13A</td>\n      <td>41120785</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>}</td>\n      <td>38</td>\n      <td>13A</td>\n      <td>41120785</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>int main() {</td>\n      <td>38</td>\n      <td>13A</td>\n      <td>41120785</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n , nn, ans = integers with ans =0</td>\n      <td>int n, nn, ans = 0;</td>\n      <td>38</td>\n      <td>13A</td>\n      <td>41120785</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the dataset by dropping rows where 'text' or 'code' is missing\n",
        "cleaned_data = data.dropna(subset=['text', 'code'])\n",
        "\n",
        "# Split the data: 80% training, 10% testing, 10% evaluation\n",
        "train_data = cleaned_data.sample(frac=0.8, random_state=42)\n",
        "remaining_data = cleaned_data.drop(train_data.index)\n",
        "test_data = remaining_data.sample(frac=0.5, random_state=42)\n",
        "eval_data = remaining_data.drop(test_data.index)\n",
        "\n",
        "# Display the number of rows in each split\n",
        "train_data.shape, test_data.shape, eval_data.shape\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:17:38.461260Z",
          "iopub.execute_input": "2025-02-26T14:17:38.461601Z",
          "iopub.status.idle": "2025-02-26T14:17:38.561502Z",
          "shell.execute_reply.started": "2025-02-26T14:17:38.461572Z",
          "shell.execute_reply": "2025-02-26T14:17:38.560641Z"
        },
        "id": "wUmL93nDpXSd",
        "outputId": "7b7438a5-1153-4592-a8ee-9012bd0c31e0"
      },
      "outputs": [
        {
          "execution_count": 55,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((172980, 7), (21622, 7), (21623, 7))"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Basic tokenizer function to split text into words (handles punctuation as well)\n",
        "def basic_tokenizer(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text.split()\n",
        "\n",
        "# Tokenize the text and code columns using the basic tokenizer\n",
        "train_text_tokens = [basic_tokenizer(text) for text in train_data['text']]\n",
        "train_code_tokens = [basic_tokenizer(code) for code in train_data['code']]\n",
        "\n",
        "# Create vocabulary mappings (word to index and index to word)\n",
        "text_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_text_tokens for word in sentence]))}\n",
        "code_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_code_tokens for word in sentence]))}\n",
        "\n",
        "# Function to convert tokens to indices\n",
        "def tokens_to_indices(tokens, vocab):\n",
        "    return [vocab.get(token, 0) for token in tokens]  # use 0 for unknown tokens\n",
        "\n",
        "# Convert the tokens to indices for the training data\n",
        "train_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in train_text_tokens]\n",
        "train_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in train_code_tokens]\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_len = 100\n",
        "train_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_text_sequences])\n",
        "train_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_code_sequences])\n",
        "\n",
        "# Repeat the process for the test and evaluation sets\n",
        "test_text_tokens = [basic_tokenizer(text) for text in test_data['text']]\n",
        "test_code_tokens = [basic_tokenizer(code) for code in test_data['code']]\n",
        "\n",
        "test_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in test_text_tokens]\n",
        "test_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in test_code_tokens]\n",
        "\n",
        "test_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_text_sequences])\n",
        "test_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_code_sequences])\n",
        "\n",
        "eval_text_tokens = [basic_tokenizer(text) for text in eval_data['text']]\n",
        "eval_code_tokens = [basic_tokenizer(code) for code in eval_data['code']]\n",
        "\n",
        "eval_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in eval_text_tokens]\n",
        "eval_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in eval_code_tokens]\n",
        "\n",
        "eval_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_text_sequences])\n",
        "eval_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_code_sequences])\n",
        "\n",
        "# Display the shapes of the sequences\n",
        "train_text_sequences.shape, train_code_sequences.shape, test_text_sequences.shape, test_code_sequences.shape, eval_text_sequences.shape, eval_code_sequences.shape\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:18:43.752600Z",
          "iopub.execute_input": "2025-02-26T14:18:43.752927Z",
          "iopub.status.idle": "2025-02-26T14:18:50.882069Z",
          "shell.execute_reply.started": "2025-02-26T14:18:43.752902Z",
          "shell.execute_reply": "2025-02-26T14:18:50.881226Z"
        },
        "id": "3FRNBpd0pXSd",
        "outputId": "3ed8d4e5-e8ab-44e0-db67-46d185c7bea5"
      },
      "outputs": [
        {
          "execution_count": 56,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((172980, 100),\n (172980, 100),\n (21622, 100),\n (21622, 100),\n (21623, 100),\n (21623, 100))"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Re-initialize the tokenizer and model parameters\n",
        "vocab_size_text = len(text_vocab) + 1  # +1 for padding\n",
        "vocab_size_code = len(code_vocab) + 1  # +1 for padding\n",
        "embedding_dim = 128\n",
        "hidden_units = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "max_len = 100\n",
        "\n",
        "# Transformer Encoder Layer\n",
        "def transformer_encoder(inputs, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(attention + ff)\n",
        "\n",
        "    return ff\n",
        "\n",
        "# Transformer Decoder Layer\n",
        "def transformer_decoder(inputs, enc_output, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Cross-attention with encoder output\n",
        "    cross_attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(attention, enc_output)\n",
        "    cross_attention = layers.Dropout(0.1)(cross_attention)\n",
        "    cross_attention = layers.LayerNormalization()(attention + cross_attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(cross_attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(cross_attention + ff)\n",
        "\n",
        "    return ff\n",
        "\n",
        "# Build the Transformer Model\n",
        "def build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len):\n",
        "    # Input layers\n",
        "    input_text = layers.Input(shape=(max_len,), dtype=tf.int32, name='text_input')\n",
        "    input_code = layers.Input(shape=(max_len,), dtype=tf.int32, name='code_input')\n",
        "\n",
        "    # Embedding layers\n",
        "    text_embedding = layers.Embedding(input_dim=vocab_size_text, output_dim=embedding_dim)(input_text)\n",
        "    code_embedding = layers.Embedding(input_dim=vocab_size_code, output_dim=embedding_dim)(input_code)\n",
        "\n",
        "    # Positional Encoding (for simplicity, we'll add sine/cosine functions as positional encodings)\n",
        "    pos_encoding = layers.Embedding(input_dim=max_len, output_dim=embedding_dim)(tf.range(max_len))\n",
        "    text_embedding += pos_encoding\n",
        "    code_embedding += pos_encoding\n",
        "\n",
        "    # Encoder stack\n",
        "    enc_output = text_embedding\n",
        "    for _ in range(num_layers):\n",
        "        enc_output = transformer_encoder(enc_output, num_heads, hidden_units)\n",
        "\n",
        "    # Decoder stack\n",
        "    dec_output = code_embedding\n",
        "    for _ in range(num_layers):\n",
        "        dec_output = transformer_decoder(dec_output, enc_output, num_heads, hidden_units)\n",
        "\n",
        "    # Final dense layer for output\n",
        "    output = layers.Dense(vocab_size_code, activation='softmax')(dec_output)\n",
        "\n",
        "    # Define the model\n",
        "    model = models.Model(inputs=[input_text, input_code], outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "transformer_model = build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len)\n",
        "\n",
        "# Compile the model\n",
        "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "transformer_model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:24:48.427069Z",
          "iopub.execute_input": "2025-02-26T14:24:48.427366Z",
          "iopub.status.idle": "2025-02-26T14:24:59.523538Z",
          "shell.execute_reply.started": "2025-02-26T14:24:48.427340Z",
          "shell.execute_reply": "2025-02-26T14:24:59.522375Z"
        },
        "id": "7kSr8hQopXSd",
        "outputId": "50148ef2-a716-4470-e3f0-b8ff87d04d43"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-d284d1fdfbc3>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Instantiate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_transformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-d284d1fdfbc3>\u001b[0m in \u001b[0;36mbuild_transformer_model\u001b[0;34m(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Embedding layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mcode_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Bad StatusOr access: INTERNAL: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_ASSERT: device-side assert triggered"
          ],
          "ename": "RuntimeError",
          "evalue": "Bad StatusOr access: INTERNAL: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_ASSERT: device-side assert triggered",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "__pnHdAepXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ngvVYkpipXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "k2Pgh2cIpXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ZZEhJ8MnpXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/kaggle/input/spoc-data/spoc-train.tsv'\n",
        "data = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Display the first few rows of the dataset to inspect\n",
        "data.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Clean the dataset by dropping rows where 'text' or 'code' is missing\n",
        "cleaned_data = data.dropna(subset=['text', 'code'])\n",
        "\n",
        "# Split the data: 80% training, 10% testing, 10% evaluation\n",
        "train_data = cleaned_data.sample(frac=0.8, random_state=42)\n",
        "remaining_data = cleaned_data.drop(train_data.index)\n",
        "test_data = remaining_data.sample(frac=0.5, random_state=42)\n",
        "eval_data = remaining_data.drop(test_data.index)\n",
        "\n",
        "# Display the number of rows in each split\n",
        "train_data.shape, test_data.shape, eval_data.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Basic tokenizer function to split text into words (handles punctuation as well)\n",
        "def basic_tokenizer(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text.split()\n",
        "\n",
        "# Tokenize the text and code columns using the basic tokenizer\n",
        "train_text_tokens = [basic_tokenizer(text) for text in train_data['text']]\n",
        "train_code_tokens = [basic_tokenizer(code) for code in train_data['code']]\n",
        "\n",
        "# Create vocabulary mappings (word to index and index to word)\n",
        "text_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_text_tokens for word in sentence]))}\n",
        "code_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_code_tokens for word in sentence]))}\n",
        "\n",
        "# Function to convert tokens to indices\n",
        "def tokens_to_indices(tokens, vocab):\n",
        "    return [vocab.get(token, 0) for token in tokens]  # use 0 for unknown tokens\n",
        "\n",
        "# Convert the tokens to indices for the training data\n",
        "train_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in train_text_tokens]\n",
        "train_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in train_code_tokens]\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_len = 100\n",
        "train_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_text_sequences])\n",
        "train_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_code_sequences])\n",
        "\n",
        "# Repeat the process for the test and evaluation sets\n",
        "test_text_tokens = [basic_tokenizer(text) for text in test_data['text']]\n",
        "test_code_tokens = [basic_tokenizer(code) for code in test_data['code']]\n",
        "\n",
        "test_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in test_text_tokens]\n",
        "test_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in test_code_tokens]\n",
        "\n",
        "test_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_text_sequences])\n",
        "test_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_code_sequences])\n",
        "\n",
        "eval_text_tokens = [basic_tokenizer(text) for text in eval_data['text']]\n",
        "eval_code_tokens = [basic_tokenizer(code) for code in eval_data['code']]\n",
        "\n",
        "eval_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in eval_text_tokens]\n",
        "eval_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in eval_code_tokens]\n",
        "\n",
        "eval_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_text_sequences])\n",
        "eval_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_code_sequences])\n",
        "\n",
        "# Display the shapes of the sequences\n",
        "train_text_sequences.shape, train_code_sequences.shape, test_text_sequences.shape, test_code_sequences.shape, eval_text_sequences.shape, eval_code_sequences.shape\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Re-initialize the tokenizer and model parameters\n",
        "vocab_size_text = len(text_vocab) + 1  # +1 for padding\n",
        "vocab_size_code = len(code_vocab) + 1  # +1 for padding\n",
        "embedding_dim = 128\n",
        "hidden_units = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "max_len = 100\n",
        "\n",
        "# Transformer Encoder Layer\n",
        "def transformer_encoder(inputs, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(attention + ff)\n",
        "\n",
        "    return ff\n",
        "\n",
        "# Transformer Decoder Layer\n",
        "def transformer_decoder(inputs, enc_output, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Cross-attention with encoder output\n",
        "    cross_attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(attention, enc_output)\n",
        "    cross_attention = layers.Dropout(0.1)(cross_attention)\n",
        "    cross_attention = layers.LayerNormalization()(attention + cross_attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(cross_attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(cross_attention + ff)\n",
        "\n",
        "    return ff\n",
        "\n",
        "# Build the Transformer Model\n",
        "def build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len):\n",
        "    # Input layers\n",
        "    input_text = layers.Input(shape=(max_len,), dtype=tf.int32, name='text_input')\n",
        "    input_code = layers.Input(shape=(max_len,), dtype=tf.int32, name='code_input')\n",
        "\n",
        "    # Embedding layers\n",
        "    text_embedding = layers.Embedding(input_dim=vocab_size_text, output_dim=embedding_dim)(input_text)\n",
        "    code_embedding = layers.Embedding(input_dim=vocab_size_code, output_dim=embedding_dim)(input_code)\n",
        "\n",
        "    # Positional Encoding (for simplicity, we'll add sine/cosine functions as positional encodings)\n",
        "    pos_encoding = layers.Embedding(input_dim=max_len, output_dim=embedding_dim)(tf.range(max_len))\n",
        "    text_embedding += pos_encoding\n",
        "    code_embedding += pos_encoding\n",
        "\n",
        "    # Encoder stack\n",
        "    enc_output = text_embedding\n",
        "    for _ in range(num_layers):\n",
        "        enc_output = transformer_encoder(enc_output, num_heads, hidden_units)\n",
        "\n",
        "    # Decoder stack\n",
        "    dec_output = code_embedding\n",
        "    for _ in range(num_layers):\n",
        "        dec_output = transformer_decoder(dec_output, enc_output, num_heads, hidden_units)\n",
        "\n",
        "    # Final dense layer for output\n",
        "    output = layers.Dense(vocab_size_code, activation='softmax')(dec_output)\n",
        "\n",
        "    # Define the model\n",
        "    model = models.Model(inputs=[input_text, input_code], outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "transformer_model = build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len)\n",
        "\n",
        "# Compile the model\n",
        "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "transformer_model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:24:34.194167Z",
          "iopub.execute_input": "2025-02-26T14:24:34.194489Z",
          "iopub.status.idle": "2025-02-26T14:24:41.387908Z",
          "shell.execute_reply.started": "2025-02-26T14:24:34.194461Z",
          "shell.execute_reply": "2025-02-26T14:24:41.387087Z"
        },
        "id": "XLV96D7ppXSe",
        "outputId": "a09cf8e5-8152-4c49-c7ca-1892d3fb7c65"
      },
      "outputs": [
        {
          "execution_count": 59,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((172980, 100),\n (172980, 100),\n (21622, 100),\n (21622, 100),\n (21623, 100),\n (21623, 100))"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ethQqjfNpXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import time\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/kaggle/input/spoc-data/spoc-train.tsv'\n",
        "data = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Clean the dataset by dropping rows where 'text' or 'code' is missing\n",
        "cleaned_data = data.dropna(subset=['text', 'code'])\n",
        "\n",
        "# Split the data: 80% training, 10% testing, 10% evaluation\n",
        "train_data = cleaned_data.sample(frac=0.8, random_state=42)\n",
        "remaining_data = cleaned_data.drop(train_data.index)\n",
        "test_data = remaining_data.sample(frac=0.5, random_state=42)\n",
        "eval_data = remaining_data.drop(test_data.index)\n",
        "\n",
        "# Basic tokenizer function to split text into words (handles punctuation as well)\n",
        "def basic_tokenizer(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text.split()\n",
        "\n",
        "# Tokenize the text and code columns using the basic tokenizer\n",
        "train_text_tokens = [basic_tokenizer(text) for text in train_data['text']]\n",
        "train_code_tokens = [basic_tokenizer(code) for code in train_data['code']]\n",
        "\n",
        "# Create vocabulary mappings (word to index and index to word)\n",
        "text_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_text_tokens for word in sentence]))}\n",
        "code_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_code_tokens for word in sentence]))}\n",
        "\n",
        "# Function to convert tokens to indices\n",
        "def tokens_to_indices(tokens, vocab):\n",
        "    return [vocab.get(token, 0) for token in tokens]  # use 0 for unknown tokens\n",
        "\n",
        "# Convert the tokens to indices for the training data\n",
        "train_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in train_text_tokens]\n",
        "train_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in train_code_tokens]\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_len = 100\n",
        "train_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_text_sequences])\n",
        "train_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_code_sequences])\n",
        "\n",
        "# Repeat the process for the test and evaluation sets\n",
        "test_text_tokens = [basic_tokenizer(text) for text in test_data['text']]\n",
        "test_code_tokens = [basic_tokenizer(code) for code in test_data['code']]\n",
        "\n",
        "test_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in test_text_tokens]\n",
        "test_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in test_code_tokens]\n",
        "\n",
        "test_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_text_sequences])\n",
        "test_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_code_sequences])\n",
        "\n",
        "eval_text_tokens = [basic_tokenizer(text) for text in eval_data['text']]\n",
        "eval_code_tokens = [basic_tokenizer(code) for code in eval_data['code']]\n",
        "\n",
        "eval_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in eval_text_tokens]\n",
        "eval_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in eval_code_tokens]\n",
        "\n",
        "eval_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_text_sequences])\n",
        "eval_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_code_sequences])\n",
        "\n",
        "# Define the Transformer model\n",
        "def transformer_encoder(inputs, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(attention + ff)\n",
        "\n",
        "    return ff\n",
        "\n",
        "def transformer_decoder(inputs, enc_output, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Cross-attention with encoder output\n",
        "    cross_attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(attention, enc_output)\n",
        "    cross_attention = layers.Dropout(0.1)(cross_attention)\n",
        "    cross_attention = layers.LayerNormalization()(attention + cross_attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(cross_attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(cross_attention + ff)\n",
        "\n",
        "    return ff\n",
        "\n",
        "def build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len):\n",
        "    input_text = layers.Input(shape=(max_len,), dtype=tf.int32, name='text_input')\n",
        "    input_code = layers.Input(shape=(max_len,), dtype=tf.int32, name='code_input')\n",
        "\n",
        "    text_embedding = layers.Embedding(input_dim=vocab_size_text, output_dim=embedding_dim)(input_text)\n",
        "    code_embedding = layers.Embedding(input_dim=vocab_size_code, output_dim=embedding_dim)(input_code)\n",
        "\n",
        "    pos_encoding = layers.Embedding(input_dim=max_len, output_dim=embedding_dim)(tf.range(max_len))\n",
        "    text_embedding += pos_encoding\n",
        "    code_embedding += pos_encoding\n",
        "\n",
        "    enc_output = text_embedding\n",
        "    for _ in range(num_layers):\n",
        "        enc_output = transformer_encoder(enc_output, num_heads, hidden_units)\n",
        "\n",
        "    dec_output = code_embedding\n",
        "    for _ in range(num_layers):\n",
        "        dec_output = transformer_decoder(dec_output, enc_output, num_heads, hidden_units)\n",
        "\n",
        "    output = layers.Dense(vocab_size_code, activation='softmax')(dec_output)\n",
        "\n",
        "    model = models.Model(inputs=[input_text, input_code], outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "transformer_model = build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim=128, hidden_units=512, num_heads=8, num_layers=6, max_len=100)\n",
        "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "transformer_model.summary()\n",
        "\n",
        "# Training function\n",
        "def train_transformer_model(model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, batch_size=32, epochs=10, learning_rate=0.001):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    epoch_times = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        indices = np.random.permutation(len(train_text_sequences))\n",
        "        train_text_sequences = train_text_sequences[indices]\n",
        "        train_code_sequences = train_code_sequences[indices]\n",
        "\n",
        "        total_loss = 0\n",
        "        num_batches = len(train_text_sequences) // batch_size\n",
        "\n",
        "        for batch_num in range(num_batches):\n",
        "            batch_start = batch_num * batch_size\n",
        "            batch_end = batch_start + batch_size\n",
        "            batch_text = train_text_sequences[batch_start:batch_end]\n",
        "            batch_code = train_code_sequences[batch_start:batch_end]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                output = model([batch_text, batch_code], training=True)\n",
        "                loss = loss_fn(batch_code, output)\n",
        "                total_loss += loss\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        epoch_time = time.time() - start_time\n",
        "        epoch_times.append(epoch_time)\n",
        "        print(f\"Epoch {epoch+1} - Time: {epoch_time:.2f}s - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        val_output = model([eval_text_sequences, eval_code_sequences], training=False)\n",
        "        val_loss = loss_fn(eval_code_sequences, val_output)\n",
        "        validation_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "\n",
        "    return epoch_times, validation_losses\n",
        "\n",
        "# Start training the model\n",
        "epoch_times, validation_losses = train_transformer_model(transformer_model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, epochs=10, batch_size=32, learning_rate=0.001)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:33:04.632308Z",
          "iopub.execute_input": "2025-02-26T14:33:04.632609Z",
          "iopub.status.idle": "2025-02-26T14:33:24.023490Z",
          "shell.execute_reply.started": "2025-02-26T14:33:04.632581Z",
          "shell.execute_reply": "2025-02-26T14:33:24.022278Z"
        },
        "id": "zbZVdwL4pXSe",
        "outputId": "2fc0a113-4595-4938-fb29-2203d5b8d652"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d9f4f7c181bf>\u001b[0m in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_transformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0mtransformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab_size_text' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'vocab_size_text' is not defined",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "mSB2uKn1pXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ftUg15elpXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "C3Pu40tkpXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import time\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/kaggle/input/spoc-data/spoc-train.tsv'\n",
        "data = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Clean the dataset by dropping rows where 'text' or 'code' is missing\n",
        "cleaned_data = data.dropna(subset=['text', 'code'])\n",
        "\n",
        "# Split the data: 80% training, 10% testing, 10% evaluation\n",
        "train_data = cleaned_data.sample(frac=0.8, random_state=42)\n",
        "remaining_data = cleaned_data.drop(train_data.index)\n",
        "test_data = remaining_data.sample(frac=0.5, random_state=42)\n",
        "eval_data = remaining_data.drop(test_data.index)\n",
        "\n",
        "# Basic tokenizer function to split text into words (handles punctuation as well)\n",
        "def basic_tokenizer(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text.split()\n",
        "\n",
        "# Tokenize the text and code columns using the basic tokenizer\n",
        "train_text_tokens = [basic_tokenizer(text) for text in train_data['text']]\n",
        "train_code_tokens = [basic_tokenizer(code) for code in train_data['code']]\n",
        "\n",
        "# Create vocabulary mappings (word to index and index to word)\n",
        "text_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_text_tokens for word in sentence]))}\n",
        "code_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_code_tokens for word in sentence]))}\n",
        "\n",
        "# Function to convert tokens to indices\n",
        "def tokens_to_indices(tokens, vocab):\n",
        "    return [vocab.get(token, 0) for token in tokens]  # use 0 for unknown tokens\n",
        "\n",
        "# Convert the tokens to indices for the training data\n",
        "train_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in train_text_tokens]\n",
        "train_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in train_code_tokens]\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_len = 100\n",
        "train_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_text_sequences])\n",
        "train_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_code_sequences])\n",
        "\n",
        "# Repeat the process for the test and evaluation sets\n",
        "test_text_tokens = [basic_tokenizer(text) for text in test_data['text']]\n",
        "test_code_tokens = [basic_tokenizer(code) for code in test_data['code']]\n",
        "\n",
        "test_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in test_text_tokens]\n",
        "test_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in test_code_tokens]\n",
        "\n",
        "test_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_text_sequences])\n",
        "test_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_code_sequences])\n",
        "\n",
        "eval_text_tokens = [basic_tokenizer(text) for text in eval_data['text']]\n",
        "eval_code_tokens = [basic_tokenizer(code) for code in eval_data['code']]\n",
        "\n",
        "eval_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in eval_text_tokens]\n",
        "eval_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in eval_code_tokens]\n",
        "\n",
        "eval_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_text_sequences])\n",
        "eval_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_code_sequences])\n",
        "\n",
        "# Define the Transformer model\n",
        "def transformer_encoder(inputs, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(attention + ff)\n",
        "\n",
        "    return ff\n",
        "\n",
        "def transformer_decoder(inputs, enc_output, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Cross-attention with encoder output\n",
        "    cross_attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(attention, enc_output)\n",
        "    cross_attention = layers.Dropout(0.1)(cross_attention)\n",
        "    cross_attention = layers.LayerNormalization()(attention + cross_attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(cross_attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(cross_attention + ff)\n",
        "\n",
        "    return ff\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:39:15.028793Z",
          "iopub.execute_input": "2025-02-26T14:39:15.029106Z",
          "iopub.status.idle": "2025-02-26T14:39:22.377378Z",
          "shell.execute_reply.started": "2025-02-26T14:39:15.029084Z",
          "shell.execute_reply": "2025-02-26T14:39:22.376703Z"
        },
        "id": "dr8m_9-spXSe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate vocab sizes\n",
        "vocab_size_text = len(text_vocab) + 1  # +1 for padding\n",
        "vocab_size_code = len(code_vocab) + 1  # +1 for padding\n",
        "vocab_size_text\n",
        "vocab_size_code"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:41:22.322671Z",
          "iopub.execute_input": "2025-02-26T14:41:22.322965Z",
          "iopub.status.idle": "2025-02-26T14:41:22.328624Z",
          "shell.execute_reply.started": "2025-02-26T14:41:22.322941Z",
          "shell.execute_reply": "2025-02-26T14:41:22.327521Z"
        },
        "id": "dQ5ndOWvpXSf",
        "outputId": "34f84d8a-ded9-4e49-d5f1-abd547d0f4c4"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "18893"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len):\n",
        "    input_text = layers.Input(shape=(max_len,), dtype=tf.int32, name='text_input')\n",
        "    input_code = layers.Input(shape=(max_len,), dtype=tf.int32, name='code_input')\n",
        "\n",
        "    text_embedding = layers.Embedding(input_dim=vocab_size_text, output_dim=embedding_dim)(input_text)\n",
        "    code_embedding = layers.Embedding(input_dim=vocab_size_code, output_dim=embedding_dim)(input_code)\n",
        "\n",
        "    pos_encoding = layers.Embedding(input_dim=max_len, output_dim=embedding_dim)(tf.range(max_len))\n",
        "    text_embedding += pos_encoding\n",
        "    code_embedding += pos_encoding\n",
        "\n",
        "    enc_output = text_embedding\n",
        "    for _ in range(num_layers):\n",
        "        enc_output = transformer_encoder(enc_output, num_heads, hidden_units)\n",
        "\n",
        "    dec_output = code_embedding\n",
        "    for _ in range(num_layers):\n",
        "        dec_output = transformer_decoder(dec_output, enc_output, num_heads, hidden_units)\n",
        "\n",
        "    output = layers.Dense(vocab_size_code, activation='softmax')(dec_output)\n",
        "\n",
        "    model = models.Model(inputs=[input_text, input_code], outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "transformer_model = build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim=128, hidden_units=512, num_heads=8, num_layers=6, max_len=100)\n",
        "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "transformer_model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:41:37.934331Z",
          "iopub.execute_input": "2025-02-26T14:41:37.934656Z",
          "iopub.status.idle": "2025-02-26T14:41:41.039281Z",
          "shell.execute_reply.started": "2025-02-26T14:41:37.934630Z",
          "shell.execute_reply": "2025-02-26T14:41:41.038084Z"
        },
        "id": "lWY1lSzSpXSf",
        "outputId": "6b2abf19-aeb9-477a-fe30-625c686ede75"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-347d0f34e61a>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_transformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mtransformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-347d0f34e61a>\u001b[0m in \u001b[0;36mbuild_transformer_model\u001b[0;34m(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0eff067a3cf0>\u001b[0m in \u001b[0;36mtransformer_encoder\u001b[0;34m(inputs, num_heads, hidden_units)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__radd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36msymbolic_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Perform shape/dtype inference.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Record a new node in the operations graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# The Node wires itself to inbound and outbound ops.  The\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36mcompute_output_spec\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mx1_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mx2_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         output_dtype = dtypes.result_type(\n\u001b[1;32m    128\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation_utils.py\u001b[0m in \u001b[0;36mbroadcast_shapes\u001b[0;34m(shape1, shape2)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0;34m\"Cannot broadcast shape, the failure dim has value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;34mf\"{shape1[i]}, which cannot be broadcasted to {shape2[i]}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot broadcast shape, the failure dim has value 128, which cannot be broadcasted to 512. Input shapes are: [None, 100, 128] and [None, 100, 512]."
          ],
          "ename": "ValueError",
          "evalue": "Cannot broadcast shape, the failure dim has value 128, which cannot be broadcasted to 512. Input shapes are: [None, 100, 128] and [None, 100, 512].",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "gpH5S7BIpXSf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training function\n",
        "def train_transformer_model(model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, batch_size=32, epochs=10, learning_rate=0.001):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    epoch_times = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        indices = np.random.permutation(len(train_text_sequences))\n",
        "        train_text_sequences = train_text_sequences[indices]\n",
        "        train_code_sequences = train_code_sequences[indices]\n",
        "\n",
        "        total_loss = 0\n",
        "        num_batches = len(train_text_sequences) // batch_size\n",
        "\n",
        "        for batch_num in range(num_batches):\n",
        "            batch_start = batch_num * batch_size\n",
        "            batch_end = batch_start + batch_size\n",
        "            batch_text = train_text_sequences[batch_start:batch_end]\n",
        "            batch_code = train_code_sequences[batch_start:batch_end]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                output = model([batch_text, batch_code], training=True)\n",
        "                loss = loss_fn(batch_code, output)\n",
        "                total_loss += loss\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        epoch_time = time.time() - start_time\n",
        "        epoch_times.append(epoch_time)\n",
        "        print(f\"Epoch {epoch+1} - Time: {epoch_time:.2f}s - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        val_output = model([eval_text_sequences, eval_code_sequences], training=False)\n",
        "        val_loss = loss_fn(eval_code_sequences, val_output)\n",
        "        validation_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "\n",
        "    return epoch_times, validation_losses\n",
        "\n",
        "# Start training the model\n",
        "epoch_times, validation_losses = train_transformer_model(transformer_model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, epochs=10, batch_size=32, learning_rate=0.001)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "K3TR11GSpXSf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "nCsbCzMwpXSf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import time\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/kaggle/input/spoc-data/spoc-train.tsv'\n",
        "data = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Clean the dataset by dropping rows where 'text' or 'code' is missing\n",
        "cleaned_data = data.dropna(subset=['text', 'code'])\n",
        "\n",
        "# Split the data: 80% training, 10% testing, 10% evaluation\n",
        "train_data = cleaned_data.sample(frac=0.8, random_state=42)\n",
        "remaining_data = cleaned_data.drop(train_data.index)\n",
        "test_data = remaining_data.sample(frac=0.5, random_state=42)\n",
        "eval_data = remaining_data.drop(test_data.index)\n",
        "\n",
        "# Basic tokenizer function to split text into words (handles punctuation as well)\n",
        "def basic_tokenizer(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text.split()\n",
        "\n",
        "# Tokenize the text and code columns using the basic tokenizer\n",
        "train_text_tokens = [basic_tokenizer(text) for text in train_data['text']]\n",
        "train_code_tokens = [basic_tokenizer(code) for code in train_data['code']]\n",
        "\n",
        "# Create vocabulary mappings (word to index and index to word)\n",
        "text_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_text_tokens for word in sentence]))}\n",
        "code_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_code_tokens for word in sentence]))}\n",
        "\n",
        "# Calculate vocab sizes\n",
        "vocab_size_text = len(text_vocab) + 1  # +1 for padding\n",
        "vocab_size_code = len(code_vocab) + 1  # +1 for padding\n",
        "\n",
        "# Function to convert tokens to indices\n",
        "def tokens_to_indices(tokens, vocab):\n",
        "    return [vocab.get(token, 0) for token in tokens]  # use 0 for unknown tokens\n",
        "\n",
        "# Convert the tokens to indices for the training data\n",
        "train_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in train_text_tokens]\n",
        "train_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in train_code_tokens]\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_len = 100\n",
        "train_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_text_sequences])\n",
        "train_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_code_sequences])\n",
        "\n",
        "# Repeat the process for the test and evaluation sets\n",
        "test_text_tokens = [basic_tokenizer(text) for text in test_data['text']]\n",
        "test_code_tokens = [basic_tokenizer(code) for code in test_data['code']]\n",
        "\n",
        "test_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in test_text_tokens]\n",
        "test_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in test_code_tokens]\n",
        "\n",
        "test_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_text_sequences])\n",
        "test_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_code_sequences])\n",
        "\n",
        "eval_text_tokens = [basic_tokenizer(text) for text in eval_data['text']]\n",
        "eval_code_tokens = [basic_tokenizer(code) for code in eval_data['code']]\n",
        "\n",
        "eval_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in eval_text_tokens]\n",
        "eval_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in eval_code_tokens]\n",
        "\n",
        "eval_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_text_sequences])\n",
        "eval_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_code_sequences])\n",
        "\n",
        "# Define the Transformer model\n",
        "def transformer_encoder(inputs, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(attention + ff)  # Ensure matching dimensions here\n",
        "\n",
        "    return ff\n",
        "\n",
        "def transformer_decoder(inputs, enc_output, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Cross-attention with encoder output\n",
        "    cross_attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(attention, enc_output)\n",
        "    cross_attention = layers.Dropout(0.1)(cross_attention)\n",
        "    cross_attention = layers.LayerNormalization()(attention + cross_attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(cross_attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(cross_attention + ff)  # Ensure matching dimensions here\n",
        "\n",
        "    return ff\n",
        "def build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len):\n",
        "    input_text = layers.Input(shape=(max_len,), dtype=tf.int32, name='text_input')\n",
        "    input_code = layers.Input(shape=(max_len,), dtype=tf.int32, name='code_input')\n",
        "\n",
        "    # Ensure embedding dimensions match hidden_units\n",
        "    text_embedding = layers.Embedding(input_dim=vocab_size_text, output_dim=hidden_units)(input_text)  # Use hidden_units\n",
        "    code_embedding = layers.Embedding(input_dim=vocab_size_code, output_dim=hidden_units)(input_code)  # Use hidden_units\n",
        "\n",
        "    pos_encoding = layers.Embedding(input_dim=max_len, output_dim=hidden_units)(tf.range(max_len))\n",
        "    text_embedding += pos_encoding\n",
        "    code_embedding += pos_encoding\n",
        "\n",
        "    enc_output = text_embedding\n",
        "    for _ in range(num_layers):\n",
        "        enc_output = transformer_encoder(enc_output, num_heads, hidden_units)\n",
        "\n",
        "    dec_output = code_embedding\n",
        "    for _ in range(num_layers):\n",
        "        dec_output = transformer_decoder(dec_output, enc_output, num_heads, hidden_units)\n",
        "\n",
        "    output = layers.Dense(vocab_size_code, activation='softmax')(dec_output)\n",
        "\n",
        "    model = models.Model(inputs=[input_text, input_code], outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "transformer_model = build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim=128, hidden_units=512, num_heads=8, num_layers=6, max_len=100)\n",
        "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "transformer_model.summary()\n",
        "\n",
        "# Training function\n",
        "def train_transformer_model(model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, batch_size=32, epochs=10, learning_rate=0.001):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    epoch_times = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        indices = np.random.permutation(len(train_text_sequences))\n",
        "        train_text_sequences = train_text_sequences[indices]\n",
        "        train_code_sequences = train_code_sequences[indices]\n",
        "\n",
        "        total_loss = 0\n",
        "        num_batches = len(train_text_sequences) // batch_size\n",
        "\n",
        "        for batch_num in range(num_batches):\n",
        "            batch_start = batch_num * batch_size\n",
        "            batch_end = batch_start + batch_size\n",
        "            batch_text = train_text_sequences[batch_start:batch_end]\n",
        "            batch_code = train_code_sequences[batch_start:batch_end]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                output = model([batch_text, batch_code], training=True)\n",
        "                loss = loss_fn(batch_code, output)\n",
        "                total_loss += loss\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        epoch_time = time.time() - start_time\n",
        "        epoch_times.append(epoch_time)\n",
        "        print(f\"Epoch {epoch+1} - Time: {epoch_time:.2f}s - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        val_output = model([eval_text_sequences, eval_code_sequences], training=False)\n",
        "        val_loss = loss_fn(eval_code_sequences, val_output)\n",
        "        validation_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "\n",
        "    return epoch_times, validation_losses\n",
        "\n",
        "# Start training the model\n",
        "epoch_times, validation_losses = train_transformer_model(transformer_model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, epochs=10, batch_size=32, learning_rate=0.001)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:48:06.521517Z",
          "iopub.execute_input": "2025-02-26T14:48:06.521857Z",
          "iopub.status.idle": "2025-02-26T14:48:31.976788Z",
          "shell.execute_reply.started": "2025-02-26T14:48:06.521834Z",
          "shell.execute_reply": "2025-02-26T14:48:31.975526Z"
        },
        "id": "9_mCcMIrpXSf",
        "outputId": "6d9beb7e-c00a-479e-8c32-8ffe2bc0aa4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,468,992\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_12 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_14 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_15 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n│                           │                        │                │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_4    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_7… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_16 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_7… │\n│                           │                        │                │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_17 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_8… │\n│                           │                        │                │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_5    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_9… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_18 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_9… │\n│                           │                        │                │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_19 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_6    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_1… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_20 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_21 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_7    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_1… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_22 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_23 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_8    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_1… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ code_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_24 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m9,673,216\u001b[0m │ code_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_13 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_9    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_26 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ dropout_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_25 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_10   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_1… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_27 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_18 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_19 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_28 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│                           │                        │                │ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_20    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_11   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_2… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_29 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_21    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_12   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_2… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_30 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_22    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_20 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_21 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_31 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_23    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_13   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_2… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_32 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_24    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_14   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_2… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_33 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_25    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_22 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_23 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_34 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_26    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_15   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_2… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_35 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_27    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_16   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_2… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_36 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_28    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_24 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_25 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_37 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_29    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_17   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_2… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_38 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_30    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_18   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_3… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_39 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_31    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_26 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_27 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_40 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_32    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_19   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_3… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_41 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_33    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_20   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m8,401,408\u001b[0m │ layer_normalization_3… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_42 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_34    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_28 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_29 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │        \u001b[38;5;34m262,656\u001b[0m │ dense_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_43 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_35    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m1,024\u001b[0m │ add_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_30 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m18893\u001b[0m)     │      \u001b[38;5;34m9,692,109\u001b[0m │ layer_normalization_3… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,468,992</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n│                           │                        │                │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7… │\n│                           │                        │                │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_8… │\n│                           │                        │                │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_5    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_9… │\n│                           │                        │                │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_6    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_7    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_8    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ code_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,673,216</span> │ code_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_9    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ dropout_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_10   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│                           │                        │                │ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_20    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_11   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_2… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_21    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_12   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_2… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_22    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_23    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_13   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_2… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_24    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_14   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_2… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_25    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_26    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_15   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_2… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_27    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_16   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_2… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_28    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_29    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_17   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_2… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_30    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_18   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_3… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_31    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_32    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_19   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_3… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_33    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_20   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,401,408</span> │ layer_normalization_3… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_34    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_35    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18893</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,692,109</span> │ layer_normalization_3… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m185,394,125\u001b[0m (707.22 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,394,125</span> (707.22 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,394,125\u001b[0m (707.22 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,394,125</span> (707.22 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n  output, from_logits = _get_logits(\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-336c64b33ff5>\u001b[0m in \u001b[0;36m<cell line: 183>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;31m# Start training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m \u001b[0mepoch_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_text_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_code_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_text_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_code_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-336c64b33ff5>\u001b[0m in \u001b[0;36mtrain_transformer_model\u001b[0;34m(model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_code\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling MultiHeadAttention.call().\n\n\u001b[1m{{function_node __wrapped__Transpose_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,100,8,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Transpose]\u001b[0m\n\nArguments received by MultiHeadAttention.call():\n  • query=tf.Tensor(shape=(32, 100, 512), dtype=float32)\n  • value=tf.Tensor(shape=(32, 100, 512), dtype=float32)\n  • key=None\n  • query_mask=None\n  • value_mask=None\n  • key_mask=None\n  • attention_mask=None\n  • return_attention_scores=False\n  • training=True\n  • use_causal_mask=False"
          ],
          "ename": "ResourceExhaustedError",
          "evalue": "Exception encountered when calling MultiHeadAttention.call().\n\n\u001b[1m{{function_node __wrapped__Transpose_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,100,8,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Transpose]\u001b[0m\n\nArguments received by MultiHeadAttention.call():\n  • query=tf.Tensor(shape=(32, 100, 512), dtype=float32)\n  • value=tf.Tensor(shape=(32, 100, 512), dtype=float32)\n  • key=None\n  • query_mask=None\n  • value_mask=None\n  • key_mask=None\n  • attention_mask=None\n  • return_attention_scores=False\n  • training=True\n  • use_causal_mask=False",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Qf03sgqIpXSf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import mixed_precision\n",
        "import time\n",
        "\n",
        "# Enable mixed precision training for memory optimization\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/kaggle/input/spoc-data/spoc-train.tsv'\n",
        "data = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Clean the dataset by dropping rows where 'text' or 'code' is missing\n",
        "cleaned_data = data.dropna(subset=['text', 'code'])\n",
        "\n",
        "# Split the data: 80% training, 10% testing, 10% evaluation\n",
        "train_data = cleaned_data.sample(frac=0.8, random_state=42)\n",
        "remaining_data = cleaned_data.drop(train_data.index)\n",
        "test_data = remaining_data.sample(frac=0.5, random_state=42)\n",
        "eval_data = remaining_data.drop(test_data.index)\n",
        "\n",
        "# Basic tokenizer function to split text into words (handles punctuation as well)\n",
        "def basic_tokenizer(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text.split()\n",
        "\n",
        "# Tokenize the text and code columns using the basic tokenizer\n",
        "train_text_tokens = [basic_tokenizer(text) for text in train_data['text']]\n",
        "train_code_tokens = [basic_tokenizer(code) for code in train_data['code']]\n",
        "\n",
        "# Create vocabulary mappings (word to index and index to word)\n",
        "text_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_text_tokens for word in sentence]))}\n",
        "code_vocab = {word: idx + 1 for idx, word in enumerate(set([word for sentence in train_code_tokens for word in sentence]))}\n",
        "\n",
        "# Calculate vocab sizes\n",
        "vocab_size_text = len(text_vocab) + 1  # +1 for padding\n",
        "vocab_size_code = len(code_vocab) + 1  # +1 for padding\n",
        "\n",
        "# Function to convert tokens to indices\n",
        "def tokens_to_indices(tokens, vocab):\n",
        "    return [vocab.get(token, 0) for token in tokens]  # use 0 for unknown tokens\n",
        "\n",
        "# Convert the tokens to indices for the training data\n",
        "train_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in train_text_tokens]\n",
        "train_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in train_code_tokens]\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_len = 100\n",
        "train_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_text_sequences])\n",
        "train_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in train_code_sequences])\n",
        "\n",
        "# Repeat the process for the test and evaluation sets\n",
        "test_text_tokens = [basic_tokenizer(text) for text in test_data['text']]\n",
        "test_code_tokens = [basic_tokenizer(code) for code in test_data['code']]\n",
        "\n",
        "test_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in test_text_tokens]\n",
        "test_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in test_code_tokens]\n",
        "\n",
        "test_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_text_sequences])\n",
        "test_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in test_code_sequences])\n",
        "\n",
        "eval_text_tokens = [basic_tokenizer(text) for text in eval_data['text']]\n",
        "eval_code_tokens = [basic_tokenizer(code) for code in eval_data['code']]\n",
        "\n",
        "eval_text_sequences = [tokens_to_indices(tokens, text_vocab) for tokens in eval_text_tokens]\n",
        "eval_code_sequences = [tokens_to_indices(tokens, code_vocab) for tokens in eval_code_tokens]\n",
        "\n",
        "eval_text_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_text_sequences])\n",
        "eval_code_sequences = np.array([seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in eval_code_sequences])\n",
        "\n",
        "# Define the Transformer model\n",
        "def transformer_encoder(inputs, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(attention + ff)  # Ensure matching dimensions here\n",
        "\n",
        "    return ff\n",
        "\n",
        "def transformer_decoder(inputs, enc_output, num_heads, hidden_units):\n",
        "    # Multi-head Self-attention\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(inputs, inputs)\n",
        "    attention = layers.Dropout(0.1)(attention)\n",
        "    attention = layers.LayerNormalization()(inputs + attention)\n",
        "\n",
        "    # Cross-attention with encoder output\n",
        "    cross_attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(attention, enc_output)\n",
        "    cross_attention = layers.Dropout(0.1)(cross_attention)\n",
        "    cross_attention = layers.LayerNormalization()(attention + cross_attention)\n",
        "\n",
        "    # Feed-forward layer\n",
        "    ff = layers.Dense(hidden_units, activation='relu')(cross_attention)\n",
        "    ff = layers.Dense(hidden_units)(ff)\n",
        "    ff = layers.Dropout(0.1)(ff)\n",
        "    ff = layers.LayerNormalization()(cross_attention + ff)  # Ensure matching dimensions here\n",
        "\n",
        "    return ff\n",
        "\n",
        "def build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim, hidden_units, num_heads, num_layers, max_len):\n",
        "    input_text = layers.Input(shape=(max_len,), dtype=tf.int32, name='text_input')\n",
        "    input_code = layers.Input(shape=(max_len,), dtype=tf.int32, name='code_input')\n",
        "\n",
        "    # Ensure embedding dimensions match hidden_units\n",
        "    text_embedding = layers.Embedding(input_dim=vocab_size_text, output_dim=hidden_units)(input_text)\n",
        "    code_embedding = layers.Embedding(input_dim=vocab_size_code, output_dim=hidden_units)(input_code)\n",
        "\n",
        "    pos_encoding = layers.Embedding(input_dim=max_len, output_dim=hidden_units)(tf.range(max_len))\n",
        "    text_embedding += pos_encoding\n",
        "    code_embedding += pos_encoding\n",
        "\n",
        "    enc_output = text_embedding\n",
        "    for _ in range(num_layers):\n",
        "        enc_output = transformer_encoder(enc_output, num_heads, hidden_units)\n",
        "\n",
        "    dec_output = code_embedding\n",
        "    for _ in range(num_layers):\n",
        "        dec_output = transformer_decoder(dec_output, enc_output, num_heads, hidden_units)\n",
        "\n",
        "    output = layers.Dense(vocab_size_code, activation='softmax')(dec_output)\n",
        "\n",
        "    model = models.Model(inputs=[input_text, input_code], outputs=output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Reduce hidden units and batch size\n",
        "hidden_units = 256  # Reduce the hidden units to 256\n",
        "batch_size = 16  # Reduce batch size to 16\n",
        "\n",
        "# Rebuild and compile the model with the updated parameters\n",
        "transformer_model = build_transformer_model(vocab_size_text, vocab_size_code, embedding_dim=128, hidden_units=hidden_units, num_heads=8, num_layers=6, max_len=100)\n",
        "transformer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "transformer_model.summary()\n",
        "\n",
        "# Training function\n",
        "def train_transformer_model(model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, batch_size=16, epochs=10, learning_rate=0.001):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    epoch_times = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        indices = np.random.permutation(len(train_text_sequences))\n",
        "        train_text_sequences = train_text_sequences[indices]\n",
        "        train_code_sequences = train_code_sequences[indices]\n",
        "\n",
        "        total_loss = 0\n",
        "        num_batches = len(train_text_sequences) // batch_size\n",
        "\n",
        "        for batch_num in range(num_batches):\n",
        "            batch_start = batch_num * batch_size\n",
        "            batch_end = batch_start + batch_size\n",
        "            batch_text = train_text_sequences[batch_start:batch_end]\n",
        "            batch_code = train_code_sequences[batch_start:batch_end]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                output = model([batch_text, batch_code], training=True)\n",
        "                loss = loss_fn(batch_code, output)\n",
        "                total_loss += loss\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        avg_loss = total_loss / num_batches\n",
        "        epoch_time = time.time() - start_time\n",
        "        epoch_times.append(epoch_time)\n",
        "        print(f\"Epoch {epoch+1} - Time: {epoch_time:.2f}s - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        val_output = model([eval_text_sequences, eval_code_sequences], training=False)\n",
        "        val_loss = loss_fn(eval_code_sequences, val_output)\n",
        "        validation_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "\n",
        "    return epoch_times, validation_losses\n",
        "\n",
        "# Start training the model with reduced batch size\n",
        "epoch_times, validation_losses = train_transformer_model(transformer_model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, epochs=10, batch_size=batch_size, learning_rate=0.001)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T14:55:42.572924Z",
          "iopub.execute_input": "2025-02-26T14:55:42.573261Z",
          "iopub.status.idle": "2025-02-26T15:37:09.366932Z",
          "shell.execute_reply.started": "2025-02-26T14:55:42.573237Z",
          "shell.execute_reply": "2025-02-26T15:37:09.365117Z"
        },
        "id": "nmXK6DUKpXSf",
        "outputId": "c4d2dcc8-ce62-4c40-8648-2c429461a005"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional_1\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m4,234,496\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_44 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_21   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ add_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_46 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ dropout_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_36    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_31 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_32 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_47 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_37    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_22   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_3… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_48 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_38    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_33 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_34 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_49 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_39    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_23   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_3… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_50 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│                           │                        │                │ dropout_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_40    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_35 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_36 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_65 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_51 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_41    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_24   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_4… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_67 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_52 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_42    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_37 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_38 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_68 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_53 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_43    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_25   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_4… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_70 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_54 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_44    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_39 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_40 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_71 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_55 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_45    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_26   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_4… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_73 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ code_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_56 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_13 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m4,836,608\u001b[0m │ code_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_46    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_45 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_41 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_27   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ add_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_42 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_76 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_74 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_58 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ dropout_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_57 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_48    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_47    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_28   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_4… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_78 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_59 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_49    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_43 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_44 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_79 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_60 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n│                           │                        │                │ dropout_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_50    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_29   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_5… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_81 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_61 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_51    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_30   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_5… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_83 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_62 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_52    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_45 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_46 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_84 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_63 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_53    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_31   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_5… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_86 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_64 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_54    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_32   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_5… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_88 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_65 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_55    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_47 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_48 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_89 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_66 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_56    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_33   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_5… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_91 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_67 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_57    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_34   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_5… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_93 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_68 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_58    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_49 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_50 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_94 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_69 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_59    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_35   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_5… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_96 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_70 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n│                           │                        │                │ dropout_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_60    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_36   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_6… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_98 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_71 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n│                           │                        │                │ dropout_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_61    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_51 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_52 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_99 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_72 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n│                           │                        │                │ dropout_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_62    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_37   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_6… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_101 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_73 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n│                           │                        │                │ dropout_101[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_63    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_38   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,103,552\u001b[0m │ layer_normalization_6… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_103 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_74 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n│                           │                        │                │ dropout_103[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_64    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_53 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ layer_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_54 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m65,792\u001b[0m │ dense_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_104 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_75 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n│                           │                        │                │ dropout_104[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_65    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │            \u001b[38;5;34m512\u001b[0m │ add_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_55 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m18893\u001b[0m)     │      \u001b[38;5;34m4,855,501\u001b[0m │ layer_normalization_6… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,234,496</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_21   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ add_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ dropout_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_36    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_37    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_22   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_3… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_38    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_39    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_23   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_3… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│                           │                        │                │ dropout_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_40    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_41    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_24   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_4… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_42    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_43    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_25   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_4… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_44    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_45    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_26   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_4… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ code_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,836,608</span> │ code_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_46    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_27   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ add_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ dropout_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_48    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_47    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_28   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_4… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_49    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n│                           │                        │                │ dropout_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_50    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_29   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_51    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_30   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_52    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_53    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_31   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_54    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_32   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_55    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_56    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_33   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_57    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_34   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_58    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_59    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_35   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n│                           │                        │                │ dropout_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_60    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_36   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n│                           │                        │                │ dropout_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_61    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n│                           │                        │                │ dropout_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_62    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_37   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n│                           │                        │                │ dropout_101[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_63    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_38   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ layer_normalization_6… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n│                           │                        │                │ dropout_103[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_64    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ dense_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n│                           │                        │                │ dropout_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_65    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18893</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,855,501</span> │ layer_normalization_6… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m53,384,909\u001b[0m (203.65 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,384,909</span> (203.65 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m53,384,909\u001b[0m (203.65 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,384,909</span> (203.65 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ddce53844589>\u001b[0m in \u001b[0;36m<cell line: 193>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# Start training the model with reduced batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m \u001b[0mepoch_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_text_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_code_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_text_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_code_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-ddce53844589>\u001b[0m in \u001b[0;36mtrain_transformer_model\u001b[0;34m(model, train_text_sequences, train_code_sequences, eval_text_sequences, eval_code_sequences, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_code\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_scope\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mnew_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         outputs = self._run_through_graph(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moperation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\u001b[0m in \u001b[0;36m_run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         ):\n\u001b[1;32m    559\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/regularization/dropout.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             return backend.random.dropout(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/random.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(inputs, rate, noise_shape, seed)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cast_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mnoise_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_concrete_noise_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     return tf.nn.experimental.stateless_dropout(\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mstateless_dropout\u001b[0;34m(x, rate, seed, rng_alg, noise_shape, name)\u001b[0m\n\u001b[1;32m   5656\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdummy_rng_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5657\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5658\u001b[0;31m   return _dropout(x=x, rate=rate, noise_shape=noise_shape,\n\u001b[0m\u001b[1;32m   5659\u001b[0m                   \u001b[0muniform_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muniform_sampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5660\u001b[0m                   \u001b[0mdummy_rng_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy_rng_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_dropout\u001b[0;34m(x, rate, noise_shape, uniform_sampler, dummy_rng_step, name, default_name)\u001b[0m\n\u001b[1;32m   5804\u001b[0m     \u001b[0;31m# Sample a uniform distribution on [0.0, 1.0) and select values larger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5805\u001b[0m     \u001b[0;31m# than or equal to `rate`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5806\u001b[0;31m     \u001b[0mrandom_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniform_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5807\u001b[0m     \u001b[0mkeep_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_tensor\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5808\u001b[0m     \u001b[0mzero_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/stateless_random_ops.py\u001b[0m in \u001b[0;36mstateless_random_uniform\u001b[0;34m(shape, seed, minval, maxval, dtype, name, alg)\u001b[0m\n\u001b[1;32m    401\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_key_counter_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         rnd = gen_stateless_random_ops_v2.stateless_random_uniform_v2(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_stateless_random_ops_v2.py\u001b[0m in \u001b[0;36mstateless_random_uniform_v2\u001b[0;34m(shape, key, counter, alg, dtype, name)\u001b[0m\n\u001b[1;32m    567\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"StatelessRandomUniformV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \"dtype\", dtype)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "CDLRB33RpXSg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "obLaTfOjpXSg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "s9y5fawrpXSg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import time\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset (replace 'spoc-train.tsv' with your actual file path)\n",
        "data = pd.read_csv('/kaggle/input/spoc-data/spoc-train.tsv', sep='\\t')\n",
        "\n",
        "# Keep only 'text' and 'code' columns\n",
        "data = data[['text', 'code']]\n",
        "\n",
        "# Check for missing values and drop them if any\n",
        "data = data.dropna()\n",
        "\n",
        "# Split into train (80%) and temp (20%)\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split temp into validation (10%) and test (10%)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Simple tokenizer (splits on spaces)\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Build vocabularies from training data\n",
        "def build_vocab(data, tokenizer):\n",
        "    tokens = set()\n",
        "    for item in data:\n",
        "        tokens.update(tokenizer(item))\n",
        "    # Reserve 0 for padding, 1 for <sos>, 2 for <eos>\n",
        "    vocab = {token: idx for idx, token in enumerate(tokens, start=3)}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<sos>'] = 1\n",
        "    vocab['<eos>'] = 2\n",
        "    return vocab\n",
        "\n",
        "# Create vocabularies\n",
        "pseudocode_vocab = build_vocab(train_data['text'], tokenize)\n",
        "cpp_vocab = build_vocab(train_data['code'], tokenize)\n",
        "\n",
        "# Inverse vocabularies for decoding (optional)\n",
        "inv_cpp_vocab = {idx: token for token, idx in cpp_vocab.items()}\n",
        "\n",
        "# Create Dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, pseudocode_vocab, cpp_vocab, tokenizer):\n",
        "        self.data = data\n",
        "        self.pseudocode_vocab = pseudocode_vocab\n",
        "        self.cpp_vocab = cpp_vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pseudocode = self.data.iloc[idx]['text']\n",
        "        cpp = self.data.iloc[idx]['code']\n",
        "        # Add special tokens\n",
        "        pseudo_tokens = ['<sos>'] + self.tokenizer(pseudocode) + ['<eos>']\n",
        "        cpp_tokens = ['<sos>'] + self.tokenizer(cpp) + ['<eos>']\n",
        "        # Convert to indices\n",
        "        pseudo_indices = [self.pseudocode_vocab.get(token, 0) for token in pseudo_tokens]\n",
        "        cpp_indices = [self.cpp_vocab.get(token, 0) for token in cpp_tokens]\n",
        "        return torch.tensor(pseudo_indices), torch.tensor(cpp_indices)\n",
        "\n",
        "# Padding function for batches\n",
        "def collate_fn(batch):\n",
        "    pseudocode, cpp = zip(*batch)\n",
        "    pseudocode = torch.nn.utils.rnn.pad_sequence(pseudocode, padding_value=0, batch_first=True)\n",
        "    cpp = torch.nn.utils.rnn.pad_sequence(cpp, padding_value=0, batch_first=True)\n",
        "    return pseudocode, cpp\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = CodeDataset(train_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "val_dataset = CodeDataset(val_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "test_dataset = CodeDataset(test_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "\n",
        "batch_size = 16  # Reduced batch size due to memory constraints\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attn, V), attn\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size = Q.size(0)\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        output, attn = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.W_o(output)\n",
        "\n",
        "\n",
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
        "\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha(x, x, x, mask)))\n",
        "        x = self.norm2(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha1(x, x, x, tgt_mask)))\n",
        "        x = self.norm2(x + self.dropout(self.mha2(x, enc_output, enc_output, src_mask)))\n",
        "        x = self.norm3(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=2048, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # Padding mask\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        nopeak_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len)).bool().to(tgt.device)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2) & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.create_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.pos_encoding(self.src_embedding(src) * math.sqrt(self.d_model)))\n",
        "        tgt_embedded = self.dropout(self.pos_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(dec_output)\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer(\n",
        "    src_vocab_size=len(pseudocode_vocab),\n",
        "    tgt_vocab_size=len(cpp_vocab),\n",
        "    d_model=512,\n",
        "    num_heads=8,\n",
        "    num_layers=6,\n",
        "    d_ff=2048,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T15:38:27.811494Z",
          "iopub.execute_input": "2025-02-26T15:38:27.811777Z",
          "iopub.status.idle": "2025-02-26T15:38:31.212697Z",
          "shell.execute_reply.started": "2025-02-26T15:38:27.811758Z",
          "shell.execute_reply": "2025-02-26T15:38:31.212043Z"
        },
        "id": "Zz0d-KNGpXSg",
        "outputId": "0317c00c-975e-425b-f2d4-30e3bd0bd3d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training samples: 172980\nValidation samples: 21622\nTest samples: 21623\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    for pseudocode, cpp in train_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Decoder input: <sos> + target[:-1]\n",
        "        # Target output: target[1:] + <eos>\n",
        "        output = model(pseudocode, cpp[:, :-1])\n",
        "        loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for pseudocode, cpp in val_loader:\n",
        "            pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Display results\n",
        "    epoch_time = end_time - start_time\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, Val Loss: {val_loss:.4f}, LR: {lr:.6f}\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T15:39:10.193435Z",
          "iopub.execute_input": "2025-02-26T15:39:10.193785Z",
          "iopub.status.idle": "2025-02-26T15:39:10.329861Z",
          "shell.execute_reply.started": "2025-02-26T15:39:10.193754Z",
          "shell.execute_reply": "2025-02-26T15:39:10.328855Z"
        },
        "id": "yrvlo0iDpXSg",
        "outputId": "d409bb1e-4e95-4611-92a6-e8c95950be8a"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-45a9f5ac1ead>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 66.12 MiB is free. Process 2433 has 14.67 GiB memory in use. Of the allocated memory 862.97 MiB is allocated by PyTorch, and 73.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ],
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 66.12 MiB is free. Process 2433 has 14.67 GiB memory in use. Of the allocated memory 862.97 MiB is allocated by PyTorch, and 73.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for pseudocode, cpp in test_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        output = model(pseudocode, cpp[:, :-1])\n",
        "        loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "        test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "A5kiCuIgpXSg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "K1MPKT5UpXSg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "HVh9f7sTpXSg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "tF2CYW4vpXSg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "4TrlCFBkpXSg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Load the dataset (replace 'spoc-train.tsv' with your actual file path)\n",
        "data = pd.read_csv('/kaggle/input/spoc-data/spoc-train.tsv', sep='\\t')\n",
        "\n",
        "# Keep only 'text' and 'code' columns\n",
        "data = data[['text', 'code']]\n",
        "\n",
        "# Check for missing values and drop them if any\n",
        "data = data.dropna()\n",
        "\n",
        "# Split into train (80%) and temp (20%)\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split temp into validation (10%) and test (10%)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Simple tokenizer (splits on spaces)\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Build vocabularies from training data\n",
        "def build_vocab(data, tokenizer):\n",
        "    tokens = set()\n",
        "    for item in data:\n",
        "        tokens.update(tokenizer(item))\n",
        "    # Reserve 0 for padding, 1 for <sos>, 2 for <eos>\n",
        "    vocab = {token: idx for idx, token in enumerate(tokens, start=3)}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<sos>'] = 1\n",
        "    vocab['<eos>'] = 2\n",
        "    return vocab\n",
        "\n",
        "# Create vocabularies\n",
        "pseudocode_vocab = build_vocab(train_data['text'], tokenize)\n",
        "cpp_vocab = build_vocab(train_data['code'], tokenize)\n",
        "\n",
        "# Inverse vocabularies for decoding (optional)\n",
        "inv_cpp_vocab = {idx: token for token, idx in cpp_vocab.items()}\n",
        "\n",
        "# Create Dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, pseudocode_vocab, cpp_vocab, tokenizer):\n",
        "        self.data = data\n",
        "        self.pseudocode_vocab = pseudocode_vocab\n",
        "        self.cpp_vocab = cpp_vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pseudocode = self.data.iloc[idx]['text']\n",
        "        cpp = self.data.iloc[idx]['code']\n",
        "        # Add special tokens\n",
        "        pseudo_tokens = ['<sos>'] + self.tokenizer(pseudocode) + ['<eos>']\n",
        "        cpp_tokens = ['<sos>'] + self.tokenizer(cpp) + ['<eos>']\n",
        "        # Convert to indices\n",
        "        pseudo_indices = [self.pseudocode_vocab.get(token, 0) for token in pseudo_tokens]\n",
        "        cpp_indices = [self.cpp_vocab.get(token, 0) for token in cpp_tokens]\n",
        "        return torch.tensor(pseudo_indices), torch.tensor(cpp_indices)\n",
        "\n",
        "# Padding function for batches\n",
        "def collate_fn(batch):\n",
        "    pseudocode, cpp = zip(*batch)\n",
        "    pseudocode = torch.nn.utils.rnn.pad_sequence(pseudocode, padding_value=0, batch_first=True)\n",
        "    cpp = torch.nn.utils.rnn.pad_sequence(cpp, padding_value=0, batch_first=True)\n",
        "    return pseudocode, cpp\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 8  # Reduced batch size due to memory constraints\n",
        "train_dataset = CodeDataset(train_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "val_dataset = CodeDataset(val_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "test_dataset = CodeDataset(test_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attn, V), attn\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size = Q.size(0)\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        output, attn = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.W_o(output)\n",
        "\n",
        "\n",
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
        "\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha(x, x, x, mask)))\n",
        "        x = self.norm2(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha1(x, x, x, tgt_mask)))\n",
        "        x = self.norm2(x + self.dropout(self.mha2(x, enc_output, enc_output, src_mask)))\n",
        "        x = self.norm3(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=128, num_heads=8, num_layers=6, d_ff=2048, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # Padding mask\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        nopeak_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len)).bool().to(tgt.device)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2) & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.create_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.pos_encoding(self.src_embedding(src) * math.sqrt(self.d_model)))\n",
        "        tgt_embedded = self.dropout(self.pos_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(dec_output)\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer(\n",
        "    src_vocab_size=len(pseudocode_vocab),\n",
        "    tgt_vocab_size=len(cpp_vocab),\n",
        "    d_model=128,\n",
        "    num_heads=8,\n",
        "    num_layers=6,\n",
        "    d_ff=2048,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T15:51:38.829528Z",
          "iopub.execute_input": "2025-02-26T15:51:38.829860Z",
          "iopub.status.idle": "2025-02-26T15:51:39.774206Z",
          "shell.execute_reply.started": "2025-02-26T15:51:38.829833Z",
          "shell.execute_reply": "2025-02-26T15:51:39.772984Z"
        },
        "id": "8l3-zDNopXSg",
        "outputId": "24100bbe-221e-4abb-fc06-1383147dc9e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training samples: 172980\nValidation samples: 21622\nTest samples: 21623\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1d03a60cab7f>\u001b[0m in \u001b[0;36m<cell line: 225>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0md_ff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m ).to(device)\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 2433 has 14.74 GiB memory in use. Of the allocated memory 935.34 MiB is allocated by PyTorch, and 64.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ],
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 2433 has 14.74 GiB memory in use. Of the allocated memory 935.34 MiB is allocated by PyTorch, and 64.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# Initialize the GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop with mixed precision\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    for pseudocode, cpp in train_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():  # Automatic mixed precision context\n",
        "            # Decoder input: <sos> + target[:-1]\n",
        "            # Target output: target[1:] + <eos>\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "\n",
        "        # Scales the loss and updates the weights\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()  # Updates the scale for the next iteration\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Validation loop with mixed precision\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for pseudocode, cpp in val_loader:\n",
        "            pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "            with autocast():  # Automatic mixed precision context\n",
        "                output = model(pseudocode, cpp[:, :-1])\n",
        "                loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Display results\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Optional: Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for pseudocode, cpp in test_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        with autocast():  # Automatic mixed precision context\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "        test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "lBslIsshpXSh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "8NgELmLXpXSh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "iEZlqnuOpXSh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UruQ8hk2pXSh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "MPcjzbLkpXSh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import os\n",
        "\n",
        "# Set the environment variable to avoid fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Load the dataset (replace 'spoc-train.tsv' with your actual file path)\n",
        "data = pd.read_csv('/kaggle/input/spoc-data/spoc-train.tsv', sep='\\t')\n",
        "\n",
        "# Keep only 'text' and 'code' columns\n",
        "data = data[['text', 'code']]\n",
        "\n",
        "# Check for missing values and drop them if any\n",
        "data = data.dropna()\n",
        "\n",
        "# Split into train (80%) and temp (20%)\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split temp into validation (10%) and test (10%)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Simple tokenizer (splits on spaces)\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Build vocabularies from training data\n",
        "def build_vocab(data, tokenizer):\n",
        "    tokens = set()\n",
        "    for item in data:\n",
        "        tokens.update(tokenizer(item))\n",
        "    # Reserve 0 for padding, 1 for <sos>, 2 for <eos>\n",
        "    vocab = {token: idx for idx, token in enumerate(tokens, start=3)}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<sos>'] = 1\n",
        "    vocab['<eos>'] = 2\n",
        "    return vocab\n",
        "\n",
        "# Create vocabularies\n",
        "pseudocode_vocab = build_vocab(train_data['text'], tokenize)\n",
        "cpp_vocab = build_vocab(train_data['code'], tokenize)\n",
        "\n",
        "# Inverse vocabularies for decoding (optional)\n",
        "inv_cpp_vocab = {idx: token for token, idx in cpp_vocab.items()}\n",
        "\n",
        "# Create Dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, pseudocode_vocab, cpp_vocab, tokenizer):\n",
        "        self.data = data\n",
        "        self.pseudocode_vocab = pseudocode_vocab\n",
        "        self.cpp_vocab = cpp_vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pseudocode = self.data.iloc[idx]['text']\n",
        "        cpp = self.data.iloc[idx]['code']\n",
        "        # Add special tokens\n",
        "        pseudo_tokens = ['<sos>'] + self.tokenizer(pseudocode) + ['<eos>']\n",
        "        cpp_tokens = ['<sos>'] + self.tokenizer(cpp) + ['<eos>']\n",
        "        # Convert to indices\n",
        "        pseudo_indices = [self.pseudocode_vocab.get(token, 0) for token in pseudo_tokens]\n",
        "        cpp_indices = [self.cpp_vocab.get(token, 0) for token in cpp_tokens]\n",
        "        return torch.tensor(pseudo_indices), torch.tensor(cpp_indices)\n",
        "\n",
        "# Padding function for batches\n",
        "def collate_fn(batch):\n",
        "    pseudocode, cpp = zip(*batch)\n",
        "    pseudocode = torch.nn.utils.rnn.pad_sequence(pseudocode, padding_value=0, batch_first=True)\n",
        "    cpp = torch.nn.utils.rnn.pad_sequence(cpp, padding_value=0, batch_first=True)\n",
        "    return pseudocode, cpp\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 8  # Reduced batch size due to memory constraints\n",
        "train_dataset = CodeDataset(train_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "val_dataset = CodeDataset(val_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "test_dataset = CodeDataset(test_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attn, V), attn\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size = Q.size(0)\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        output, attn = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.W_o(output)\n",
        "\n",
        "\n",
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
        "\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha(x, x, x, mask)))\n",
        "        x = self.norm2(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha1(x, x, x, tgt_mask)))\n",
        "        x = self.norm2(x + self.dropout(self.mha2(x, enc_output, enc_output, src_mask)))\n",
        "        x = self.norm3(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=256, num_heads=4, num_layers=4, d_ff=1024, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # Padding mask\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        nopeak_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len)).bool().to(tgt.device)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2) & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.create_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.pos_encoding(self.src_embedding(src) * math.sqrt(self.d_model)))\n",
        "        tgt_embedded = self.dropout(self.pos_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(dec_output)\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer(\n",
        "    src_vocab_size=len(pseudocode_vocab),\n",
        "    tgt_vocab_size=len(cpp_vocab),\n",
        "    d_model=256,  # Reduced hidden units for memory efficiency\n",
        "    num_heads=4,  # Reduced number of attention heads\n",
        "    num_layers=4,  # Reduced number of layers\n",
        "    d_ff=1024,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# Initialize the GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop with mixed precision\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    for pseudocode, cpp in train_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():  # Automatic mixed precision context\n",
        "            # Decoder input: <sos> + target[:-1]\n",
        "            # Target output: target[1:] + <eos>\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "\n",
        "        # Scales the loss and updates the weights\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()  # Updates the scale for the next iteration\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Validation loop with mixed precision\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for pseudocode, cpp in val_loader:\n",
        "            pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "            with autocast():  # Automatic mixed precision context\n",
        "                output = model(pseudocode, cpp[:, :-1])\n",
        "                loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Display results\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Optional: Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for pseudocode, cpp in test_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        with autocast():  # Automatic mixed precision context\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "        test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T15:53:43.136791Z",
          "iopub.execute_input": "2025-02-26T15:53:43.137136Z",
          "iopub.status.idle": "2025-02-26T15:53:44.160507Z",
          "shell.execute_reply.started": "2025-02-26T15:53:43.137110Z",
          "shell.execute_reply": "2025-02-26T15:53:44.159409Z"
        },
        "id": "5LOA_CKVpXSh",
        "outputId": "96159d7d-6b24-4ac9-98a7-fd2e4e61fa53"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training samples: 172980\nValidation samples: 21622\nTest samples: 21623\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-5e2f68bba261>\u001b[0m in \u001b[0;36m<cell line: 229>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0md_ff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m ).to(device)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;31m# Loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 2433 has 14.74 GiB memory in use. Of the allocated memory 935.34 MiB is allocated by PyTorch, and 64.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ],
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 2433 has 14.74 GiB memory in use. Of the allocated memory 935.34 MiB is allocated by PyTorch, and 64.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "FwHs9KD8pXSh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "d6QR0xxVpXSh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "H2eQPFgopXSh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import os\n",
        "\n",
        "# Set the environment variable to avoid fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Load the dataset (replace 'spoc-train.tsv' with your actual file path)\n",
        "data = pd.read_csv('/kaggle/input/spoc-data/spoc-train.tsv', sep='\\t')\n",
        "\n",
        "# Keep only 'text' and 'code' columns\n",
        "data = data[['text', 'code']]\n",
        "\n",
        "# Check for missing values and drop them if any\n",
        "data = data.dropna()\n",
        "\n",
        "# Split into train (80%) and temp (20%)\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split temp into validation (10%) and test (10%)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Simple tokenizer (splits on spaces)\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Build vocabularies from training data\n",
        "def build_vocab(data, tokenizer):\n",
        "    tokens = set()\n",
        "    for item in data:\n",
        "        tokens.update(tokenizer(item))\n",
        "    # Reserve 0 for padding, 1 for <sos>, 2 for <eos>\n",
        "    vocab = {token: idx for idx, token in enumerate(tokens, start=3)}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<sos>'] = 1\n",
        "    vocab['<eos>'] = 2\n",
        "    return vocab\n",
        "\n",
        "# Create vocabularies\n",
        "pseudocode_vocab = build_vocab(train_data['text'], tokenize)\n",
        "cpp_vocab = build_vocab(train_data['code'], tokenize)\n",
        "\n",
        "# Inverse vocabularies for decoding (optional)\n",
        "inv_cpp_vocab = {idx: token for token, idx in cpp_vocab.items()}\n",
        "\n",
        "# Create Dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, pseudocode_vocab, cpp_vocab, tokenizer):\n",
        "        self.data = data\n",
        "        self.pseudocode_vocab = pseudocode_vocab\n",
        "        self.cpp_vocab = cpp_vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pseudocode = self.data.iloc[idx]['text']\n",
        "        cpp = self.data.iloc[idx]['code']\n",
        "        # Add special tokens\n",
        "        pseudo_tokens = ['<sos>'] + self.tokenizer(pseudocode) + ['<eos>']\n",
        "        cpp_tokens = ['<sos>'] + self.tokenizer(cpp) + ['<eos>']\n",
        "        # Convert to indices\n",
        "        pseudo_indices = [self.pseudocode_vocab.get(token, 0) for token in pseudo_tokens]\n",
        "        cpp_indices = [self.cpp_vocab.get(token, 0) for token in cpp_tokens]\n",
        "        return torch.tensor(pseudo_indices), torch.tensor(cpp_indices)\n",
        "\n",
        "# Padding function for batches\n",
        "def collate_fn(batch):\n",
        "    pseudocode, cpp = zip(*batch)\n",
        "    pseudocode = torch.nn.utils.rnn.pad_sequence(pseudocode, padding_value=0, batch_first=True)\n",
        "    cpp = torch.nn.utils.rnn.pad_sequence(cpp, padding_value=0, batch_first=True)\n",
        "    return pseudocode, cpp\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 8  # Reduced batch size due to memory constraints\n",
        "train_dataset = CodeDataset(train_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "val_dataset = CodeDataset(val_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "test_dataset = CodeDataset(test_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attn, V), attn\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size = Q.size(0)\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        output, attn = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.W_o(output)\n",
        "\n",
        "\n",
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
        "\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha(x, x, x, mask)))\n",
        "        x = self.norm2(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha1(x, x, x, tgt_mask)))\n",
        "        x = self.norm2(x + self.dropout(self.mha2(x, enc_output, enc_output, src_mask)))\n",
        "        x = self.norm3(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=128, num_heads=2, num_layers=2, d_ff=512, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # Padding mask\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        nopeak_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len)).bool().to(tgt.device)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2) & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.create_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.pos_encoding(self.src_embedding(src) * math.sqrt(self.d_model)))\n",
        "        tgt_embedded = self.dropout(self.pos_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(dec_output)\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer(\n",
        "    src_vocab_size=len(pseudocode_vocab),\n",
        "    tgt_vocab_size=len(cpp_vocab),\n",
        "    d_model=128,  # Further reduced hidden units for memory efficiency\n",
        "    num_heads=2,  # Reduced number of attention heads\n",
        "    num_layers=2,  # Reduced number of layers\n",
        "    d_ff=512,  # Reduced feed-forward dimension\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# Initialize the GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop with mixed precision\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    for pseudocode, cpp in train_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():  # Automatic mixed precision context\n",
        "            # Decoder input: <sos> + target[:-1]\n",
        "            # Target output: target[1:] + <eos>\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "\n",
        "        # Scales the loss and updates the weights\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()  # Updates the scale for the next iteration\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Validation loop with mixed precision\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for pseudocode, cpp in val_loader:\n",
        "            pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "            with autocast():  # Automatic mixed precision context\n",
        "                output = model(pseudocode, cpp[:, :-1])\n",
        "                loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Display results\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Optional: Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for pseudocode, cpp in test_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        with autocast():  # Automatic mixed precision context\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "        test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T16:05:28.127587Z",
          "iopub.execute_input": "2025-02-26T16:05:28.127872Z",
          "iopub.status.idle": "2025-02-26T16:05:29.026276Z",
          "shell.execute_reply.started": "2025-02-26T16:05:28.127852Z",
          "shell.execute_reply": "2025-02-26T16:05:29.025050Z"
        },
        "id": "m62OyIGXpXSh",
        "outputId": "b7c0b102-6990-4392-c710-cd1754700a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training samples: 172980\nValidation samples: 21622\nTest samples: 21623\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-98f9074076ba>\u001b[0m in \u001b[0;36m<cell line: 229>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0md_ff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Reduced feed-forward dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m ).to(device)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;31m# Loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 2433 has 14.74 GiB memory in use. Of the allocated memory 935.34 MiB is allocated by PyTorch, and 64.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ],
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 2433 has 14.74 GiB memory in use. Of the allocated memory 935.34 MiB is allocated by PyTorch, and 64.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Tvo1E3FtpXSi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "4lQqqsFlpXSi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import os\n",
        "\n",
        "# Set the environment variable to avoid fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Load the dataset (replace 'spoc-train.tsv' with your actual file path)\n",
        "data = pd.read_csv('/kaggle/input/spoc-data/spoc-train.tsv', sep='\\t')\n",
        "\n",
        "# Keep only 'text' and 'code' columns\n",
        "data = data[['text', 'code']]\n",
        "\n",
        "# Check for missing values and drop them if any\n",
        "data = data.dropna()\n",
        "\n",
        "# Split into train (80%) and temp (20%)\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split temp into validation (10%) and test (10%)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Simple tokenizer (splits on spaces)\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Build vocabularies from training data\n",
        "def build_vocab(data, tokenizer):\n",
        "    tokens = set()\n",
        "    for item in data:\n",
        "        tokens.update(tokenizer(item))\n",
        "    # Reserve 0 for padding, 1 for <sos>, 2 for <eos>\n",
        "    vocab = {token: idx for idx, token in enumerate(tokens, start=3)}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<sos>'] = 1\n",
        "    vocab['<eos>'] = 2\n",
        "    return vocab\n",
        "\n",
        "# Create vocabularies\n",
        "pseudocode_vocab = build_vocab(train_data['text'], tokenize)\n",
        "cpp_vocab = build_vocab(train_data['code'], tokenize)\n",
        "\n",
        "# Inverse vocabularies for decoding (optional)\n",
        "inv_cpp_vocab = {idx: token for token, idx in cpp_vocab.items()}\n",
        "\n",
        "# Create Dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, pseudocode_vocab, cpp_vocab, tokenizer):\n",
        "        self.data = data\n",
        "        self.pseudocode_vocab = pseudocode_vocab\n",
        "        self.cpp_vocab = cpp_vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pseudocode = self.data.iloc[idx]['text']\n",
        "        cpp = self.data.iloc[idx]['code']\n",
        "        # Add special tokens\n",
        "        pseudo_tokens = ['<sos>'] + self.tokenizer(pseudocode) + ['<eos>']\n",
        "        cpp_tokens = ['<sos>'] + self.tokenizer(cpp) + ['<eos>']\n",
        "        # Convert to indices\n",
        "        pseudo_indices = [self.pseudocode_vocab.get(token, 0) for token in pseudo_tokens]\n",
        "        cpp_indices = [self.cpp_vocab.get(token, 0) for token in cpp_tokens]\n",
        "        return torch.tensor(pseudo_indices), torch.tensor(cpp_indices)\n",
        "\n",
        "# Padding function for batches\n",
        "def collate_fn(batch):\n",
        "    pseudocode, cpp = zip(*batch)\n",
        "    pseudocode = torch.nn.utils.rnn.pad_sequence(pseudocode, padding_value=0, batch_first=True)\n",
        "    cpp = torch.nn.utils.rnn.pad_sequence(cpp, padding_value=0, batch_first=True)\n",
        "    return pseudocode, cpp\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 8  # Reduced batch size due to memory constraints\n",
        "train_dataset = CodeDataset(train_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "val_dataset = CodeDataset(val_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "test_dataset = CodeDataset(test_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attn, V), attn\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size = Q.size(0)\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        output, attn = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.W_o(output)\n",
        "\n",
        "\n",
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
        "\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha(x, x, x, mask)))\n",
        "        x = self.norm2(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha1(x, x, x, tgt_mask)))\n",
        "        x = self.norm2(x + self.dropout(self.mha2(x, enc_output, enc_output, src_mask)))\n",
        "        x = self.norm3(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=64, num_heads=2, num_layers=2, d_ff=256, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # Padding mask\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        nopeak_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len)).bool().to(tgt.device)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2) & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.create_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.pos_encoding(self.src_embedding(src) * math.sqrt(self.d_model)))\n",
        "        tgt_embedded = self.dropout(self.pos_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(dec_output)\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer(\n",
        "    src_vocab_size=len(pseudocode_vocab),\n",
        "    tgt_vocab_size=len(cpp_vocab),\n",
        "    d_model=64,  # Further reduced hidden units for memory efficiency\n",
        "    num_heads=2,  # Reduced number of attention heads\n",
        "    num_layers=2,  # Reduced number of layers\n",
        "    d_ff=256,  # Reduced feed-forward dimension\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# Initialize the GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop with mixed precision\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    for pseudocode, cpp in train_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():  # Automatic mixed precision context\n",
        "            # Decoder input: <sos> + target[:-1]\n",
        "            # Target output: target[1:] + <eos>\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "\n",
        "        # Scales the loss and updates the weights\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()  # Updates the scale for the next iteration\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Validation loop with mixed precision\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for pseudocode, cpp in val_loader:\n",
        "            pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "            with autocast():  # Automatic mixed precision context\n",
        "                output = model(pseudocode, cpp[:, :-1])\n",
        "                loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Display results\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Optional: Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for pseudocode, cpp in test_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        with autocast():  # Automatic mixed precision context\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "        test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-26T18:06:19.077500Z",
          "iopub.execute_input": "2025-02-26T18:06:19.077884Z",
          "iopub.status.idle": "2025-02-26T18:06:29.489093Z",
          "shell.execute_reply.started": "2025-02-26T18:06:19.077855Z",
          "shell.execute_reply": "2025-02-26T18:06:29.487775Z"
        },
        "id": "99S1TG4KpXSi",
        "outputId": "f27a3a74-9418-4173-953f-087e320987b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training samples: 172980\nValidation samples: 21622\nTest samples: 21623\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "<ipython-input-1-7779245bf22d>:244: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n<ipython-input-1-7779245bf22d>:257: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():  # Automatic mixed precision context\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7779245bf22d>\u001b[0m in \u001b[0;36m<cell line: 248>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;31m# Decoder input: <sos> + target[:-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# Target output: target[1:] + <eos>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpseudocode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7779245bf22d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_embedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menc_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_embedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7779245bf22d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7779245bf22d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7779245bf22d>\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: value cannot be converted to type at::Half without overflow"
          ],
          "ename": "RuntimeError",
          "evalue": "value cannot be converted to type at::Half without overflow",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "pi-XkzZopXSi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***MODEL WITH SOME OUTPUT***"
      ],
      "metadata": {
        "id": "uNJ6apwhpXSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Set the environment variable to avoid fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Load the dataset (replace 'spoc-train.tsv' with your actual file path)\n",
        "data = pd.read_csv('/kaggle/input/spoc-data/spoc-train.tsv', sep='\\t')\n",
        "\n",
        "# Keep only 'text' and 'code' columns\n",
        "data = data[['text', 'code']]\n",
        "\n",
        "# Check for missing values and drop them if any\n",
        "data = data.dropna()\n",
        "\n",
        "# Split into train (80%) and temp (20%)\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split temp into validation (10%) and test (10%)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "\n",
        "# Simple tokenizer (splits on spaces)\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Build vocabularies from training data\n",
        "def build_vocab(data, tokenizer):\n",
        "    tokens = set()\n",
        "    for item in data:\n",
        "        tokens.update(tokenizer(item))\n",
        "    # Reserve 0 for padding, 1 for <sos>, 2 for <eos>\n",
        "    vocab = {token: idx for idx, token in enumerate(tokens, start=3)}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<sos>'] = 1\n",
        "    vocab['<eos>'] = 2\n",
        "    return vocab\n",
        "\n",
        "# Create vocabularies\n",
        "pseudocode_vocab = build_vocab(train_data['text'], tokenize)\n",
        "cpp_vocab = build_vocab(train_data['code'], tokenize)\n",
        "\n",
        "# Inverse vocabularies for decoding (optional)\n",
        "inv_cpp_vocab = {idx: token for token, idx in cpp_vocab.items()}\n",
        "\n",
        "# Create Dataset class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, data, pseudocode_vocab, cpp_vocab, tokenizer):\n",
        "        self.data = data\n",
        "        self.pseudocode_vocab = pseudocode_vocab\n",
        "        self.cpp_vocab = cpp_vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pseudocode = self.data.iloc[idx]['text']\n",
        "        cpp = self.data.iloc[idx]['code']\n",
        "        # Add special tokens\n",
        "        pseudo_tokens = ['<sos>'] + self.tokenizer(pseudocode) + ['<eos>']\n",
        "        cpp_tokens = ['<sos>'] + self.tokenizer(cpp) + ['<eos>']\n",
        "        # Convert to indices\n",
        "        pseudo_indices = [self.pseudocode_vocab.get(token, 0) for token in pseudo_tokens]\n",
        "        cpp_indices = [self.cpp_vocab.get(token, 0) for token in cpp_tokens]\n",
        "        return torch.tensor(pseudo_indices), torch.tensor(cpp_indices)\n",
        "\n",
        "# Padding function for batches\n",
        "def collate_fn(batch):\n",
        "    pseudocode, cpp = zip(*batch)\n",
        "    pseudocode = torch.nn.utils.rnn.pad_sequence(pseudocode, padding_value=0, batch_first=True)\n",
        "    cpp = torch.nn.utils.rnn.pad_sequence(cpp, padding_value=0, batch_first=True)\n",
        "    return pseudocode, cpp\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 8  # Reduced batch size due to memory constraints\n",
        "train_dataset = CodeDataset(train_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "val_dataset = CodeDataset(val_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "test_dataset = CodeDataset(test_data, pseudocode_vocab, cpp_vocab, tokenize)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "# Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attn, V), attn\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        batch_size = Q.size(0)\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        output, attn = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.W_o(output)\n",
        "\n",
        "\n",
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n",
        "\n",
        "\n",
        "# Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha(x, x, x, mask)))\n",
        "        x = self.norm2(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        x = self.norm1(x + self.dropout(self.mha1(x, x, x, tgt_mask)))\n",
        "        x = self.norm2(x + self.dropout(self.mha2(x, enc_output, enc_output, src_mask)))\n",
        "        x = self.norm3(x + self.dropout(self.ff(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=64, num_heads=2, num_layers=2, d_ff=256, dropout=0.1, max_len=512):\n",
        "        super().__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)  # Padding mask\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        nopeak_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len)).bool().to(tgt.device)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2) & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.create_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.pos_encoding(self.src_embedding(src) * math.sqrt(self.d_model)))\n",
        "        tgt_embedded = self.dropout(self.pos_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(dec_output)\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer(\n",
        "    src_vocab_size=len(pseudocode_vocab),\n",
        "    tgt_vocab_size=len(cpp_vocab),\n",
        "    d_model=64,  # Further reduced hidden units for memory efficiency\n",
        "    num_heads=2,  # Reduced number of attention heads\n",
        "    num_layers=2,  # Reduced number of layers\n",
        "    d_ff=128,  # Reduced feed-forward dimension\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:03:39.198741Z",
          "iopub.execute_input": "2025-02-27T08:03:39.199141Z",
          "iopub.status.idle": "2025-02-27T08:03:40.014918Z",
          "shell.execute_reply.started": "2025-02-27T08:03:39.199117Z",
          "shell.execute_reply": "2025-02-27T08:03:40.014014Z"
        },
        "id": "sE3oop04pXSi",
        "outputId": "5e4370ec-c4e9-4341-c2f8-26c7cadb7513"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training samples: 172980\nValidation samples: 21622\nTest samples: 21623\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training loop without mixed precision\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    for pseudocode, cpp in train_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Decoder input: <sos> + target[:-1]\n",
        "        # Target output: target[1:] + <eos>\n",
        "        output = model(pseudocode, cpp[:, :-1])\n",
        "        loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for pseudocode, cpp in val_loader:\n",
        "            pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "            output = model(pseudocode, cpp[:, :-1])\n",
        "            loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Display results\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, Val Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:03:49.683201Z",
          "iopub.execute_input": "2025-02-27T08:03:49.683521Z",
          "iopub.status.idle": "2025-02-27T08:35:27.572990Z",
          "shell.execute_reply.started": "2025-02-27T08:03:49.683496Z",
          "shell.execute_reply": "2025-02-27T08:35:27.572003Z"
        },
        "id": "S-czU2rKpXSj",
        "outputId": "484f83c3-2863-43de-dc6a-2c4543440843"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5, Time: 363.58s, Val Loss: 2.1023\nEpoch 2/5, Time: 360.98s, Val Loss: 1.8708\nEpoch 3/5, Time: 360.65s, Val Loss: 1.7683\nEpoch 4/5, Time: 360.75s, Val Loss: 1.7206\nEpoch 5/5, Time: 360.35s, Val Loss: 1.8546\nTest Loss: 1.8228\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for pseudocode, cpp in test_loader:\n",
        "        pseudocode, cpp = pseudocode.to(device), cpp.to(device)\n",
        "        output = model(pseudocode, cpp[:, :-1])\n",
        "        loss = criterion(output.view(-1, len(cpp_vocab)), cpp[:, 1:].contiguous().view(-1))\n",
        "        test_loss += loss.item()\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:49:19.164659Z",
          "iopub.execute_input": "2025-02-27T08:49:19.165053Z",
          "iopub.status.idle": "2025-02-27T08:49:34.428199Z",
          "shell.execute_reply.started": "2025-02-27T08:49:19.165026Z",
          "shell.execute_reply": "2025-02-27T08:49:34.427285Z"
        },
        "id": "KKQW64O9pXSj",
        "outputId": "c18aa74b-229f-44fb-d4f2-a1d20be1cc88"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Test Loss: 1.8228\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"transformer_seq2seq_testing0.2.pth\")\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:55:02.903095Z",
          "iopub.execute_input": "2025-02-27T08:55:02.903458Z",
          "iopub.status.idle": "2025-02-27T08:55:02.955105Z",
          "shell.execute_reply.started": "2025-02-27T08:55:02.903433Z",
          "shell.execute_reply": "2025-02-27T08:55:02.954408Z"
        },
        "id": "4ItM06HRpXSj",
        "outputId": "fba4d265-454c-45a7-fbe0-b6ccb5325143"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Model saved successfully.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model.load_state_dict(torch.load(\"/kaggle/input/test0.1/pytorch/test0.1/1/transformer_seq2seq_testing0.1.pth\"))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "CDlpgVlnpXSj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse vocabularies for decoding (for C++ code)\n",
        "inv_code_vocab = {idx: token for token, idx in cpp_vocab.items()}\n",
        "\n",
        "def generate_code(model, input_text, text_vocab, code_vocab, max_len=100):\n",
        "    \"\"\"\n",
        "    Generate C++ code from pseudocode using the trained Transformer model.\n",
        "\n",
        "    :param model: The trained Transformer model.\n",
        "    :param input_text: The input pseudocode as a string.\n",
        "    :param text_vocab: Vocabulary for pseudocode (text).\n",
        "    :param code_vocab: Vocabulary for C++ code.\n",
        "    :param max_len: Maximum length of the generated code.\n",
        "    :return: The generated C++ code as a string.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Tokenize the input text (pseudocode)\n",
        "    input_tokens = ['<sos>'] + input_text.split() + ['<eos>']\n",
        "\n",
        "    # Convert tokens to indices using the text vocabulary\n",
        "    input_indices = [text_vocab.get(token, 0) for token in input_tokens]\n",
        "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "    # Start decoding the output C++ code\n",
        "    generated_code = []\n",
        "    tgt_input = torch.tensor([text_vocab['<sos>']]).unsqueeze(0).to(device)  # Initial target token\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            # Get the model's prediction for the next token\n",
        "            output = model(input_tensor, tgt_input)\n",
        "\n",
        "            # Get the predicted token (with highest probability) for each position\n",
        "            predicted_token_idx = output.argmax(dim=-1)[:, -1].item()  # Get the last token prediction\n",
        "\n",
        "            # If we predict the <eos> token, stop generating\n",
        "            if predicted_token_idx == code_vocab['<eos>']:\n",
        "                break\n",
        "\n",
        "            # Add the predicted token to the output sequence\n",
        "            generated_code.append(inv_code_vocab.get(predicted_token_idx, '<unk>'))\n",
        "\n",
        "            # Update the target input (append the predicted token for the next step)\n",
        "            tgt_input = torch.cat([tgt_input, torch.tensor([[predicted_token_idx]]).to(device)], dim=-1)\n",
        "\n",
        "    # Join the generated tokens into a single string\n",
        "    generated_code_str = ' '.join(generated_code)\n",
        "    return generated_code_str\n",
        "\n",
        "# Example usage:\n",
        "input_text = \"for i from 1 to n do\"\n",
        "generated_code = generate_code(model, input_text, pseudocode_vocab, cpp_vocab, max_len=100)\n",
        "print(\"Generated C++ code:\", generated_code)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:55:08.520910Z",
          "iopub.execute_input": "2025-02-27T08:55:08.521233Z",
          "iopub.status.idle": "2025-02-27T08:55:08.587238Z",
          "shell.execute_reply.started": "2025-02-27T08:55:08.521205Z",
          "shell.execute_reply": "2025-02-27T08:55:08.586499Z"
        },
        "id": "XpYxC3PMpXSj",
        "outputId": "05f7496b-2c89-4267-feeb-7907fc86cc61"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Generated C++ code: for (int i = 1; i <= n; i++) {\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"create integers x1, y1, x2, y2\"\n",
        "generated_code = generate_code(model, input_text, pseudocode_vocab, cpp_vocab, max_len=100)\n",
        "print(\"Generated C++ code:\", generated_code)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:55:16.738889Z",
          "iopub.execute_input": "2025-02-27T08:55:16.739183Z",
          "iopub.status.idle": "2025-02-27T08:55:16.767955Z",
          "shell.execute_reply.started": "2025-02-27T08:55:16.739163Z",
          "shell.execute_reply": "2025-02-27T08:55:16.767213Z"
        },
        "id": "N3MVr-TRpXSj",
        "outputId": "09603343-b466-454a-eb40-6b79081d2011"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Generated C++ code: int n, m, k;\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"read s\"\n",
        "generated_code = generate_code(model, input_text, pseudocode_vocab, cpp_vocab, max_len=100)\n",
        "print(\"Generated C++ code:\", generated_code)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:55:29.588059Z",
          "iopub.execute_input": "2025-02-27T08:55:29.588333Z",
          "iopub.status.idle": "2025-02-27T08:55:29.611678Z",
          "shell.execute_reply.started": "2025-02-27T08:55:29.588313Z",
          "shell.execute_reply": "2025-02-27T08:55:29.610869Z"
        },
        "id": "Nuj40Lj2pXSj",
        "outputId": "35e26af8-2ae1-40f6-d5c1-153e015cacf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Generated C++ code: cin >> s;\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define the function that uses the generate_code logic\n",
        "def generate_cpp_code_from_pseudocode(input_text):\n",
        "    generated_code = generate_code(model, input_text, pseudocode_vocab, cpp_vocab, max_len=100)\n",
        "    return generated_code\n",
        "\n",
        "# Create a Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_cpp_code_from_pseudocode,          # Function to run\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter pseudocode here...\"),  # Input text box for pseudocode\n",
        "    outputs=gr.Textbox(label=\"Generated C++ Code\"),  # Output text box for generated C++ code\n",
        "    title=\"Pseudocode to C++ Code Generator\",  # Title of the interface\n",
        "    description=\"Enter pseudocode and get the corresponding C++ code generated using the Transformer model.\",\n",
        "    theme=\"compact\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:56:53.988040Z",
          "iopub.execute_input": "2025-02-27T08:56:53.988366Z",
          "iopub.status.idle": "2025-02-27T08:56:59.417088Z",
          "shell.execute_reply.started": "2025-02-27T08:56:53.988342Z",
          "shell.execute_reply": "2025-02-27T08:56:59.416304Z"
        },
        "id": "l8moDn17pXSj",
        "outputId": "577086f3-656d-4cd8-b9b2-4583b8277968"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:1096: UserWarning: Cannot load compact. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/compact (Request ID: Root=1-67c028d9-28cbc996374980e966882819;ad245594-c15e-4f89-8367-2abbc13e4ddd)\n\nSorry, we can't find the page you are looking for.\n  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "* Running on local URL:  http://127.0.0.1:7860\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://57ed0cbbb7bf79fefa.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<div><iframe src=\"https://57ed0cbbb7bf79fefa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
          },
          "metadata": {}
        },
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-27T08:55:47.636774Z",
          "iopub.execute_input": "2025-02-27T08:55:47.637129Z",
          "iopub.status.idle": "2025-02-27T08:55:58.492149Z",
          "shell.execute_reply.started": "2025-02-27T08:55:47.637101Z",
          "shell.execute_reply": "2025-02-27T08:55:58.491213Z"
        },
        "id": "6hATaQELpXSj",
        "outputId": "e435cddd-0680-4dec-85e5-258c9f8cf678"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting gradio\n  Downloading gradio-5.19.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.7.2 (from gradio)\n  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\nCollecting markupsafe~=2.0 (from gradio)\n  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.11.0a2)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.2->gradio) (2024.12.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.2->gradio) (14.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.29.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.19.0-py3-none-any.whl (62.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\n  Attempting uninstall: markupsafe\n    Found existing installation: MarkupSafe 3.0.2\n    Uninstalling MarkupSafe-3.0.2:\n      Successfully uninstalled MarkupSafe-3.0.2\nSuccessfully installed fastapi-0.115.8 ffmpy-0.5.0 gradio-5.19.0 gradio-client-1.7.2 markupsafe-2.1.5 python-multipart-0.0.20 ruff-0.9.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}